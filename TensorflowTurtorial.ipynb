{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Tensorflow \n",
    "## 1.1. Tensorflow là gì?\n",
    "\n",
    "Tensorflow là một thư viện mã nguồn mở làm việc dựa trên lập trình *luồng dữ liệu* (dataflow) thông qua các nhiệm vụ. Đây là một thư viện toán học được sử dụng nhiều trong các ứng dụng của học máy chẳng hạn như xây dựng các mạng nơ ron, các thuật toán phân loại kNN (k-Nearest Neighbor), SVM (Support Vector Machine),.... và được sử dụng trong các dự án nghiên cứu cũng như sản phâm của google và thay thế các thư viện gần đây.\n",
    "\n",
    "## 1.2. Đặc trưng của tensorflow.\n",
    "\n",
    "Tensorflow là luồng của dữ liệu được thể hiện qua một đồ thị tính toán. Khi xây dựng một model tensorflow chúng ta thường tách biệt 2 phần riêng rẽ đó là: \n",
    "\n",
    "1. Xây dựng đồ thị tính toán:  Một đồ thị sẽ bao gồm các node và các cạnh. Node của đồ thị sẽ thể hiện chức năng tính toán (chẳng hạn phép cộng, trừ, nhân, chia,...) và cách cạnh thể hiện dữ liệu tính toán, thường là các dữ liệu nhiều chiều hay còn gọi là tensor được kết nối với nhau thông qua các node.\n",
    "\n",
    "\n",
    "2. Thực thi các luồng tính toán trên đồ thị: Đồ thị tính toán mà ta có mới chỉ là một bản thiết kế của mô hình. Chúng ta cần chạy bản thiết kế đó bằng cách kích hoạt một session để thực thi các operation của đồ thị. Các thực thi này sẽ cần được truyền dữ liệu đầu vào để làm nguyên liệu trả về kết quả ở đầu ra.\n",
    "\n",
    "\n",
    "## 1.3. Giới thiệu tensor.\n",
    "\n",
    "Tensor là một kiểu dữ liệu cho phép lưu trữ được số chiều tùy ý, nó có thể là đại lượng vô hướng, vector, mảng 1 chiều, mảng 2 chiều hoặc mảng kích thước n chiều. Sau đây là các ví dụ về tensor:\n",
    "\n",
    "* 0 chiều (đại lượng vô hướng): 1\n",
    "* 1 chiều: [1, 2, 3]\n",
    "* 2 chiều: [[1, 2], [3, 4]]\n",
    "* 3 chiều: [[[1, 2], [3, 4]], \n",
    "            [[5, 6], [7, 8]]]\n",
    "\n",
    "# 2. Các đối tượng trong tensor\n",
    "\n",
    "## 2.1. Hằng số\n",
    "\n",
    "Là giá trị cố định trong tensorflow được khởi tạo thông qua hàm `tf.constant()`. Chúng ta sẽ không thể thay đổi được giá trị của một hằng số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ta nhận thấy mặc dù đã khởi tạo giá trị cho a = 5 nhưng khi hiển thị giá trị của a = 0. Đó là vì chúng ta mới chỉ tạo ra đồ thị gồm một operation là a nhưng vẫn chưa thực thi đồ thị đó. Do đó a vẫn đang giữ giá trị mặc định là 0. Khi thực thi đồ thị chúng ta cần tạo ra một session để run operation a nhằm kích hoạt luồng xử lý, khi đó giá trị a = 5. Lưu ý trong một graph thì một dữ liệu (có thể là hằng, biến, placeholder) đều là 1 operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ngoài ra ta có thể sử dụng lệnh `eval()` để đánh giá các node trong một đồ thị. Nhưng trước đó ta phải khai báo một session như là mặc định để chạy được graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.as_default()\n",
    "    print(a.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ngoài ra ta có thể sử dụng lệnh tf.InteractiveSession() để tạo ra một session trong trạng thái mặc định (luôn được sử dụng) để đánh giá đồ thị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession()\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.2. Biến\n",
    "\n",
    "Trái ngược với hằng. Biến là là giá thay đổi trong một đồ thị. Thông thường trong mạng nơ ron thì biến chính là ma trận hệ số của hàm loss function. Biến sẽ luôn có giá trị khởi tạo ban đầu để kích hoạt thuật toán gradient. Để tạo ra một variable trong tensorflow ta sử dụng hàm `tf.Variabel()` hoặc `tf.get_variable()`.\n",
    "\n",
    "* Khởi tạo một biến thông qua hàm tf.Variabel():\n",
    "\n",
    "Cú pháp: `tf.Variabel(value = value, name = name)`. Trong đó value là các giá trị của biến và name là tên của operation thể hiện trên đồ thị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Khởi tạo một giá trị Variable trong tensorflow\n",
    "v = tf.Variable([1, 2, 3], name = 'vector')\n",
    "m_2D = tf.Variable([[1, 2], [3, 4]], name = 'matrix_2D')\n",
    "m_nD = tf.Variable(tf.zeros([2, 2, 2]), name = 'matrix_nD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Khởi tạo một biến thông qua hàm tf.get_variable():\n",
    "\n",
    "Cú pháp:`tf.get_variable(initializer = value, name = name)`. Trong đó initializer là giá trị của biến và name là tên của operation trên đồ thị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Khởi tạo một giá trị Variable trong tensorflow\n",
    "gv_v = tf.get_variable(initializer = [1, 2, 3], name = 'vector')\n",
    "gv_m_2D = tf.get_variable(initializer = [[1, 2], [3, 4]], name = 'matrix_2D')\n",
    "gv_m_nD = tf.get_variable(initializer = tf.zeros([2, 2, 2]), name = 'matrix_nD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Các biến sau khi được khởi tạo nếu muốn sử dụng được sẽ cần được kích hoạt thông qua 1 session bằng lệnh `tf.global_variables_initializer()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3]), array([[1, 2],\n",
      "       [3, 4]]), array([[[0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo tất cả trong 1 lần:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([gv_v, gv_m_2D, gv_m_nD]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Trong trường hợp chỉ muốn khởi tạo các biến trong danh sách cụ thể ta có thể dùng hàm `tf.variables_initializer()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3]), array([[1, 2],\n",
      "       [3, 4]]), array([[[0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo tất cả trong 1 lần:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([v, m_2D, m_nD]))\n",
    "    print(sess.run([v, m_2D, m_nD]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.3. Placeholder\n",
    "\n",
    "Là các biến mà giá trị ban đầu không được khởi tạo trong lúc tạo graph mà được truyền vào từ như tập data input để chạy một mô hình. Chẳng hạn một mô hình được xây dựng dựa trên một bộ dữ liệu có thể được sử dụng lại cho nhiều bộ dữ liệu khác có cùng đặc điểm. Khi đó giá trị mà ta cần truyền vào mô hình chính là các placeholder. Đồ thị của mô hình có thể được giữ nguyên (số lớp, số lượng đơn vị trong từng lớp, kích thước đầu vào, đầu ra,...) ta thu được các hệ số mới. Hàm số để khởi tạo placeholder là `tf.placeholder(dtype, shape)`.\n",
    "Giả sử bên dưới ta khởi tạo một placeholder x có kích thước 2x3. Chúng ta cần tính phép nhân ma trận x với một ma trận hằng số y kích thước 3x1. Ta làm như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [2, 3])\n",
    "y = tf.constant([[1], [2], [3]], tf.float32) #lưu ý phải kiểu dữ liệu của y và x phải trùng nhau\n",
    "y_hat = tf.matmul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Khi đó một operation y_hat được khởi tạo bằng với phép nhân ma trận x và y thông qua hàm `tf.matmul()`. Một điều ta dễ nhận thấy đó là giá trị của x không được khởi tạo mặc định như đối với kiểu biến thông thường (`tf.variable()`) mà chỉ khi ta kích hoạt đồ thị tại operation y_hat thì chúng ta mới truyền vào giá trị của x thông qua tham số feed_dict có dạng của một dictionary trong python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[14.],\n",
      "       [32.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run([y_hat], feed_dict = {x: [[1, 2, 3], [4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Khi ta cần thay một bộ dữ liệu khác thì chúng ta sẽ thay đổi giá trị của x trong feed_dict. Kết quả đầu ra sẽ thay đổi nhưng kích thước của ma trận đầu ra không thay đổi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[16.],\n",
      "       [18.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run([y_hat], feed_dict = {x: [[3, 5, 1], [2, 5, 2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.4. Các tensor đặc biệt \n",
    "\n",
    "Cũng giống như numpy, tensor sẽ có những kiểu ma trận đặc biệt để giúp khởi tạo tensor nhanh hơn bao gồm: ma trận 0, ma trận 1, ma trận đơn vị, ma trận ngẫu nhiên,....\n",
    "\n",
    "**1. zeros tensor**\n",
    "\n",
    "`tf.zeros(shape = shape, dtype = dtype)` với dtype là kiểu biến và shape là kích thước của tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "t_zeros = tf.zeros([2, 3, 2],tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t_zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hoặc ta có thể tạo một zero tensor có kích thước bằng với một tensor cho trước thông qua hàm \n",
    "`tf.zeros_like(original_tensor)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "t_origin = tf.constant([[[1, 2], \n",
    "                         [3, 4]],\n",
    "                        [[5, 6],\n",
    "                         [7, 8]]])\n",
    "t_zeros = tf.zeros_like(t_origin)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t_zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**2. one tensor**\n",
    "\n",
    "Hoàn toàn tương tự như zeros tensor, one tensor cũng có cú pháp như sau: `tf.ones(shape = shape, dtype = dtype)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor ones:[[[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "\n",
      "tensor ones like:[[[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "t_ones = tf.ones([2, 3, 2],tf.float32)\n",
    "t_ones_like = tf.ones_like(t_ones)\n",
    "with tf.Session() as sess:\n",
    "    print('tensor ones:' + str(sess.run(t_ones)) + '\\n')\n",
    "    print('tensor ones like:' + str(sess.run(t_ones_like)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**3. tensor đơn vị**\n",
    "\n",
    "Tensor đơn vị sẽ có các phần tử là một ma trận đơn vị và được khởi tạo thông qua hàm:\n",
    "\n",
    "`\n",
    "tf.eye(\n",
    "    num_rows,\n",
    "    num_columns=None,\n",
    "    batch_shape=None,\n",
    "    dtype=tf.float32,\n",
    "    name=None\n",
    ")\n",
    "`\n",
    "\n",
    "Trong đó num_rows, num_columns lần lượt là số dòng và số cột, batch_shape là kích thước của tensor theo batch. Nếu batch_shape = [3, 3] thì tensor sẽ bao gồm 3 dòng và 3 cột trong đó một phần tử ứng với 1 dòng và 1 cột là một ma trận kích thước num_rows x num_columns. dtype là kiểu biến và name là tên của node. Kích thước của tensor khi biểu diễn đến từng phần tử của ma trận là [batch_shape, num_rows, num_columns]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "t_eye = tf.eye(3, 3, [1], tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t_eye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**4.tensor ngẫu nhiên**\n",
    "\n",
    "Là tensor có các phần tử được tạo ra một cách ngẫu nhiên. Thông thường là phân phối `gaussian` với kì vọng và phương sai xác định. Hàm `tf.random_normal()` sẽ được sử dụng để tạo ra một tensor ngẫu nhiên có cú pháp:\n",
    "`\n",
    "tf.random_normal(\n",
    "    shape,\n",
    "    mean=0.0,\n",
    "    stddev=1.0,\n",
    "    dtype=tf.float32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "`\n",
    "\n",
    "Trong đó shape là kích thước của tensor, mean là trung bình, stddev là độ lệch chuẩn, giá trị seed là 1 số nguyên dương sẽ qui định lần chạy lại sau sẽ đưa ra kết quả như lần chạy trước. Mặc định của seed là các kết quả mỗi lần chạy sẽ không tái lập."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.371148 11.631453  9.860746]\n",
      " [ 9.928445  8.940451  7.29932 ]]\n"
     ]
    }
   ],
   "source": [
    "t_random = tf.random_normal([2, 3], mean = 9, stddev = 2)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ngoài ra ta còn có `tf.random_poisson()` sử dụng cho phân phối poisson và `tf.random_uniform()` sử dụng cho phân phối đều. Có cú pháp lần lượt là:\n",
    "\n",
    "`\n",
    "tf.random_poisson(\n",
    "    lam, #tham số đặc trưng xác định phân phối poisson\n",
    "    shape, #kích thước của tensor\n",
    "    dtype=tf.float32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "`\n",
    "\n",
    "và \n",
    "\n",
    "`\n",
    "tf.random_uniform(\n",
    "    shape, #kích thước của tensor\n",
    "    minval=0, #giá trị nhỏ nhất\n",
    "    maxval=None, #giá trị lớn nhất\n",
    "    dtype=tf.float32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 1., 4.],\n",
      "       [3., 2., 2.]], dtype=float32), array([[1.5300908 , 1.3826258 , 0.26188993],\n",
      "       [0.5182018 , 1.3891945 , 0.26262975]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "t_rand_pois = tf.random_poisson(lam = 2, shape = [2, 3])\n",
    "t_rand_unif = tf.random_uniform(shape = [2, 3], minval = 0, maxval = 2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([t_rand_pois, t_rand_unif]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.5. Các toán tử \n",
    "\n",
    "**1. Phép cộng/ trừ**\n",
    "\n",
    "Được thực hiện qua hàm `tf.add()` như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, -1]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(1)\n",
    "y = tf.constant(2)\n",
    "z = tf.add(x, y)\n",
    "t = tf.add(x, -y)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([z, t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**2. Phép nhân**\n",
    "\n",
    "Được thực hiện qua hàm `tf.multiply()` như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(1)\n",
    "y = tf.constant(2)\n",
    "z = tf.multiply(x, y)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**3. Phép nhân ma trận**\n",
    "\n",
    "Sử dụng hàm `tf.matmul()` có cú pháp như sau:\n",
    "\n",
    "`tf.matmul(\n",
    "    a,\n",
    "    b,\n",
    "    transpose_a=False,\n",
    "    transpose_b=False,\n",
    "    adjoint_a=False,\n",
    "    adjoint_b=False,\n",
    "    a_is_sparse=False,\n",
    "    b_is_sparse=False,\n",
    "    name=None\n",
    ")`\n",
    "\n",
    "Trong đó a, b lần lượt là các tensor bên trái và tensor bên phải. Lưu ý là trong trường hợp tensor 2D thì số cột của a phải bằng số dòng của b; trường hợp tensor 3D thì kích thước của a phải bằng kích thước của b khi chuyển vị của 2 chiều cuối cùng. Các tham số transpose_a, transpose_b khi được thiệt lập True (mặc định False) lần lượt có ý nghĩa có chuyển vị trước khi nhân hay không. Các tham số a_is_sparse, b_is_sparse = True lần lượt có ý nghĩa coi a, b như là các biểu diễn của ma trận sparse hay không (mặc định là không). Bên dưới là các ví dụ:\n",
    "\n",
    "* Trường hợp tensor 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  62  68  74]\n",
      " [152 174 196 218]\n",
      " [248 286 324 362]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = tf.constant(np.arange(12), shape = [3, 4])\n",
    "y = tf.constant(np.arange(16), shape = [4, 4])\n",
    "z = tf.matmul(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Trường hợp tensor 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 120  130  140  150]\n",
      "  [ 320  355  390  425]\n",
      "  [ 520  580  640  700]\n",
      "  [ 720  805  890  975]]\n",
      "\n",
      " [[3120 3230 3340 3450]\n",
      "  [3820 3955 4090 4225]\n",
      "  [4520 4680 4840 5000]\n",
      "  [5220 5405 5590 5775]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = tf.constant(np.arange(40), shape = [2, 4, 5]) \n",
    "y = tf.constant(np.arange(40), shape = [2, 5, 4]) \n",
    "z = tf.matmul(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.5. Các hàm đặc biệt\n",
    "\n",
    "**1. Trung bình**\n",
    "\n",
    "Để tính trung bình của một tensor ta sẽ sử dụng hàm `tf.reduce_mean()`:\n",
    "\n",
    "`tf.reduce_mean(\n",
    "    input_tensor,\n",
    "    axis=None,\n",
    "    keepdims=None,\n",
    "    name=None\n",
    ")`\n",
    "\n",
    "input_tensor là tensor cần tính trung bình. axis là chiều cần tính trung bình. Nếu axis = None thì mặc định tính trung bình của toàn bộ các phần tử của tensor mà không xét đến chiều. Nếu tính trung bình theo một chiều nào đó thì số chiều của kết quả đầu ra sẽ giảm đi 1 do theo chiều đó tensor đều có 1 phần tử đại diện. keepdims = True có tác dụng giữ nguyên số chiều so với input__tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, array([[[4, 5, 6]]])]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "y = tf.reduce_mean(x)\n",
    "z = tf.reduce_mean(x, axis = 1, keepdims = True)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y, z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**2. Min/Max**\n",
    "\n",
    "Tương tự như cách tính trung bình. Ta sẽ sử dụng hàm `tf.reduce_min()` hoặc `tf.reduce_max()` có cú pháp lần lượt:\n",
    "\n",
    "`tf.reduce_max(\n",
    "    input_tensor,\n",
    "    axis=None,\n",
    "    keepdims=None,\n",
    "    name=None\n",
    ")`\n",
    "\n",
    "\n",
    "`tf.reduce_max(\n",
    "    input_tensor,\n",
    "    axis=None,\n",
    "    keepdims=None,\n",
    "    name=None\n",
    ")`\n",
    "\n",
    "Kết quả trả về sẽ là giá trị min hoặc max theo các chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, array([[[1, 2, 3]]])]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "y = tf.reduce_min(x)\n",
    "z = tf.reduce_min(x, axis = 1, keepdims = True)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y, z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**3. exponential**\n",
    "\n",
    "Hàm mũ cơ số tự nhiên được sử dụng phổ biến trong học máy chẳng hạn như trong hồi qui logistic, hàm softmax, .... Chúng ta sẽ sử dụng hàm `tf.exp()` để tính giá trị của cơ số mũ đối với 1 tensor. Kết quả trả về là một tensor chứa các phần tử là lũy thừa cơ số tự nhiên ($e$) của phần tử tương ứng trên tensor gốc. Cú pháp của hàm đơn giản như sau:\n",
    "\n",
    "`tf.exp(x, name=None)`\n",
    "\n",
    "Lưu ý rằng x là tensor có kiểu định dạng nằm trong các kiếu `half, float32, float64, complex64, complex128`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[2.7182817e+00, 7.3890562e+00, 2.0085537e+01],\n",
      "        [5.4598152e+01, 1.4841316e+02, 4.0342880e+02],\n",
      "        [1.0966332e+03, 2.9809580e+03, 8.1030840e+03]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]], dtype = tf.float32)\n",
    "y = tf.exp(x)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**4. Hàm relu**\n",
    "\n",
    "Hàm relu có công thức là $y = max(0, x)$. Đây là một hàm activation được sử dụng khá phổ biến trong các mô hình học máy trong những năm gần đây để thay thế cho hàm sigmoid bởi đạo hàm của nó tồn tại hầu khắp nơi (trừ điểm 0) và khi $x > 0$ đạo hàm chỉ nhận giá trị là 1 nên sẽ tiết kiệm chi phí tính toán đồng thồi không bị triệt tiêu. Trong khi hạn chế của đạo hàm sigmoid đó là mỗi lần $x$ thay đổi sẽ phải tính lại đạo hàm và sẽ bị triệt tiêu khi giá trị của $x$ vô cùng lớn hoặc vô cùng nhỏ. Chúng ta có thể sử dụng hàm `tf.nn.relu()` để tính giá trị relu của một tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1., 0., 3.],\n",
      "        [4., 5., 0.],\n",
      "        [7., 0., 9.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1, -2, 3], [4, 5, -6], [7, -8, 9]]], dtype = tf.float32)\n",
    "y = tf.nn.relu(x)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**5. Hàm softmax**\n",
    "\n",
    "Được sử dụng để ước lượng xác xuất xảy ra của một class. Chẳng hạn chúng ta có bài toán phân loại $C$ class. Sau khi thiết lập mạng nơ ron ta tính được layer cuối cùng là vector $\\mathbf{z} \\in \\mathbb{R}^{C}$. Khi đó giá trị của hàm softmax ứng với class $i$ sẽ là:\n",
    "\n",
    "$$a_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^C \\exp(z_j)}, ~~ \\forall i = 1, 2, \\dots, C$$\n",
    "\n",
    "Một tính chất ta dễ nhận thấy là tổng các giá trị softmax của toàn bộ các class phải bằng 1.\n",
    "\n",
    "softmax có thể được tính toán thông qua hàm `tf.nn.softmax()` với cú pháp:\n",
    "\n",
    "`tf.nn.softmax(logits, dim=-1, name=None)`\n",
    "\n",
    "Trong đó logits là một tensor có các kiểu biến `half, float32, float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5.7628046e-04, 5.7628046e-04, 1.5664927e-03, 4.2581689e-03,\n",
      "       1.1574903e-02, 3.1463847e-02, 8.5527599e-02, 2.3248814e-01,\n",
      "       6.3196826e-01], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 1, 2, 3, 4, 5, 6, 7, 8], dtype = tf.float32)\n",
    "y = tf.nn.softmax(x)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Kiểm tra tổng giá trị softmax trả về."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 1, 2, 3, 4, 5, 6, 7, 8], dtype = tf.float32)\n",
    "y = tf.nn.softmax(x)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reduce_sum(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**6. argument min/max**\n",
    "\n",
    "Hàm này sẽ trả về số thứ tự tương ứng theo một chiều nào đó trong một tensor có giá trị là lớn nhất hoặc nhỏ nhất. Cú pháp:\n",
    "\n",
    "`tf.argmax(input, axis=None, name=None, dimension=None)`\n",
    "\n",
    "`tf.argmin(input, axis=None, name=None, dimension=None)`\n",
    "\n",
    "trong đó input là tensor và axis là chiều để tính argmax hoặc argmin. Trường hợp thông thường được áp dụng là vector (tensor-1D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 9, 0, 2, 3, 4, 5, 6, 7, 8], dtype = tf.float32)\n",
    "y = tf.argmin(x)\n",
    "z = tf.argmax(x)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y, z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2.6. Đồ thị\n",
    "\n",
    "### 2.6.1. Các tạo một đồ thị\n",
    "\n",
    "Đồ thị là một cấu phần không thể thiếu trong một model tensorflow. Trong một đồ thị sẽ bao gồm rất nhiều các operation object, mỗi một operation object đại diện cho một tính toán.\n",
    "\n",
    "Chúng ta có 2 cách chính để tạo ra một graph đó là thông qua hàm `tf.Graph()` hoặc `tf.get_default_graph()`. \n",
    "\n",
    "Khi gọi hàm `tf.get_default_graph()` thì một graph mặc định luôn được tạo ra. Khi đó để thêm một phần tử operation mới vào graph mặc định ta chỉ cần khởi tạo operation. Chẳng hạn như bên dưới ta sẽ tạo ra một operation và kiểm tra xem operation này có phải là một thành phần của graph mặc định hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is one part of default graph\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(5)\n",
    "if x.graph is tf.get_default_graph():\n",
    "    print('x is one part of default graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Kết quả cho thấy một operation khi được tạo ra luông là một phần của graph mặc định. \n",
    "\n",
    "Khi khởi tạo một graph từ hàm `tf.Graph()` thì graph đó không mặc định. Do đó để thêm một operation vào graph thì ta phải chuyển graph vừa khởi tạo sang mặc định bằng hàm `as_default()` và tạo các operation trong graph đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is one part of default graph\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.constant(5)\n",
    "    if x.graph is g:\n",
    "        print('x is one part of default graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.6.2. Xuất đồ thị trên tensorboard\n",
    "\n",
    "Tensorboard làm một công cụ giúp ta hiển thị, theo dõi và quản lý các đồ thị từ một luồng xử lý dữ liệu tensorflow. Để cài đặt tensorboard chúng ta gõ lệnh.\n",
    "\n",
    "`pip install tensorboard=1.8.0`\n",
    "\n",
    "lưu ý sau dấu bằng là version của tensorboard. Nên cài version của tensorboard bằng với version của tensorflow để tránh conflict. Trong tensorboard có một vài hàm quan trọng có chức năng như sau:\n",
    "\n",
    "* `tf.summary.scalar`: Được gắn vào các nodes để lưu lại các giá trị của learning rate và loss sau mỗi lần xử lý.\n",
    "\n",
    "* `tf.summary.histogram`: Vẽ biểu đồ histogram phân phối của các trọng số và gradients từ một layer cụ thể.\n",
    "\n",
    "* `tf.summary.merge_all`: Sát nhập các thống kê của toàn bộ các nodes trong graph vào một bản thống kê dữ liệu chung.\n",
    "\n",
    "* `tf.summary.FileWriter`: Lưu toàn bộ các thống kê của đồ thị vào ổ đĩa.\n",
    "\n",
    "Chúng ta sẽ quan tâm đến hàm `tf.summary.FileWriter()` nhất bởi hàm này cho phép ta lưu và đọc một graph trên tensorboard. `tf.summary.FileWriter()` có cú pháp như sau:\n",
    "\n",
    "`tf.summary.FileWriter(folder directory, graph)`\n",
    "\n",
    "Trong đó folder directory là địa chỉ của thư mục mà ta sẽ lưu đồ thị. graph là đồ thị cần lưu vào disk. Lưu ý đồ thị này luôn phải để mặc định để có thể thêm các phần operation vào trong nó.\n",
    "\n",
    "Bên dưới chúng ta tạo ra một graph mặc định và lưu vào ổ đĩa ở folder cùng thư mục cha với file hiện hành có tên là `first_graph_logs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(2, name = 'x_variabel')\n",
    "y = tf.Variable(4, name = 'y_variabel')\n",
    "z = tf.multiply(x, y)\n",
    "\n",
    "#Khởi tạo một writer để lưu graph mặc định vào ổ đĩa\n",
    "writer = tf.summary.FileWriter('first_graph_logs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    #Khởi tạo toàn bộ các biến\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #Thêm operation z vào graph mặc định\n",
    "    sess.run(z)\n",
    "#Đóng writer    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sau khi chạy chương trình trên một folder mới tên là first_graph_logs được tạo trong cùng thư mục với file hiện hành và lưu toàn bộ các kết quả xử lý và cấu trúc của graph. Để đọc được graph này ta vào cửa số command line trỏ tới folder cha chứa file hiện hành và gõ lệnh:\n",
    "\n",
    "`tensorboard --logdir first_graph_logs`\n",
    "\n",
    "--logdirs là tên của tham số và giá trị phía sau là đường dẫn tới folder lưu trữ graph. Khi đó kết chương trình sẽ hiển thị dòng logs:\n",
    "\n",
    "`TensorBoard 1.8.0 at http://laptopTCC-PC:6006 (Press CTRL+C to quit)`\n",
    "\n",
    "Ta copy đường link và truy cập thông qua trình duyệt để xem cấu trúc của graph.\n",
    "\n",
    "# 3. Xây dựng mạng nơ ron  trên tensorflow\n",
    "\n",
    "Bên dưới ta sẽ sử dụng tensorflow để xây dựng một mạng nơ ron network phân loại các loại hoa trong tập dữ liệu iris. Đây là bộ dữ liệu bao gồm 120 quan sát trên tập train và 30 quan sát trên tập test về dữ liệu Kích thước chiều dài và chiều rộng của cánh và tán của 3 loài hoa iris khác nhau. Dựa vào kích thước các loài hoa ta sẽ xây dựng một model mạng nơ ron để phân loại đúng loài hoa về nhóm của chúng. \n",
    "\n",
    "Quá trình xây dựng mạng nơ ron sẽ trải qua 4 bước:\n",
    "\n",
    "1. Chuẩn bị dữ liệu đầu vào.\n",
    "2. Xây dựng mạng nơ ron.\n",
    "3. Thiết lập hàm loss function và phương pháp tối ưu gradient descent.\n",
    "4. Fitting mô hình và đánh giá kết quả.\n",
    "\n",
    "Các bước lần lượt như bên dưới:\n",
    "\n",
    "**1. Chuẩn bị dữ liệu **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as req\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#set up parameter\n",
    "TRAIN = 'iris_training.csv'\n",
    "TRAIN_URL = 'http://download.tensorflow.org/data/iris_training.csv'\n",
    "TEST = 'iris_testing.csv'\n",
    "TEST_URL = 'http://download.tensorflow.org/data/iris_test.csv'\n",
    "input_shape = 4\n",
    "n_classes = 3\n",
    "\n",
    "def loadfile(filename, link):\n",
    "    if not os.path.exists(filename):\n",
    "        raw = req.urlopen(link).read().decode('utf-8')\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(raw)\n",
    "            \n",
    "    data = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=filename,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "    #normalize biến dự báo theo phân phối chuẩn\n",
    "    mu = np.mean(data.data, axis = 0)\n",
    "    sigma = (np.std(data.data, axis=0))\n",
    "    predictor = (data.data - mu) / sigma\n",
    "    \n",
    "    #Chuyển biến mục tiêu sang dạng onehot endcoder\n",
    "#     target = np.eye(len(data.target), n_classes, dtype = np.float32)[data.target]\n",
    "    target = data.target\n",
    "    return {'predictor': predictor, 'target': target}\n",
    "\n",
    "train = loadfile(TRAIN, TRAIN_URL)\n",
    "test = loadfile(TEST, TEST_URL)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, input_shape])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filename_queue = tf.train.string_input_producer([TRAIN, TEST])\n",
    "# reader = tf.TextLineReader(skip_header_lines = True)\n",
    "# key, value = reader.read(filename_queue)\n",
    "\n",
    "# record_defaults = [[0.], [0.], [0.], [0.], [0.]]\n",
    "\n",
    "# col1, col2, col3, col4, col5 = tf.decode_csv(\n",
    "#     value, record_defaults=record_defaults)\n",
    "\n",
    "# features = tf.stack([col1, col2, col3, col4])\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#   # Start populating the filename queue.\n",
    "#   coord = tf.train.Coordinator()\n",
    "#   threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "# #   for i in range(120):\n",
    "#     # Retrieve a single instance:\n",
    "#   example, label = sess.run([features, col5])\n",
    "\n",
    "#   coord.request_stop()\n",
    "#   coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X và y lần lượt là 2 placeholder được sử dụng để chứa biến dự báo và và biến được dự báo. Kích thước của nó có height bằng None ngụ ý rằng ta có thể đưa vào bao nhiêu quan sát tùy ý. Điều này thuận lợi cho fitting model theo các batch_size khác nhau ở bước 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**2. Xây dựng mạng nơ ron**\n",
    "\n",
    "Ta nhận thấy các giá trị cần tunning trong mô hình là các weights và biases. Do đó trong mạng nơ ron ta sẽ xây dựng các layer  dựa trên ma trận hệ số và vector chệch. Lưu ý chúng ta phải khai báo các ma trận hệ số và vector chệch dưới dạng Variable để thuật toán tối ưu có thể hiểu được đây là các giá trị cần cập nhật.\n",
    "Mạng nơ ron sẽ có gồm 3 layer với kích thước mỗi layer như sau:\n",
    "\n",
    "* layer 1: 200 units với kích thước ma trận [input_shape, 10].\n",
    "\n",
    "* layer 2: 300 units với kích thước ma trận [10, 15].\n",
    "\n",
    "* layer 3: 400 units với kích thước ma trận [15, 20].\n",
    "\n",
    "* output layer: là một flatten layer. Do đó nó có kích thước ma trận trọng số là [20, 1].\n",
    "\n",
    "Do output của layer trước sẽ làm input của layer sau nên ta hoàn toàn xác định được shape của input dựa vào ouput của layer trước. Để thỏa mãn các phép nhân ma trận thực hiện được thì các kích thước ma trận hệ số ở mỗi layer phải được sắp xếp sao cho width của layer liền trước phải bằng height của layer liền sau. Các vector chệch sẽ có height = 1 và width phải bằng width của ma trận trọng số thuộc cùng 1 layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/46264133/weights-and-biases-not-updating-in-tensorflow\n",
    "weights = {\n",
    "    'l1': tf.Variable(tf.random_normal([input_shape, 10])),\n",
    "    'l2': tf.Variable(tf.random_normal([10, 15])),                              \n",
    "    'l3': tf.Variable(tf.random_normal([15, 20])),\n",
    "    'out': tf.Variable(tf.random_normal([20, 1]))\n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'l1': tf.Variable(tf.random_normal([1, 10])),\n",
    "    'l2': tf.Variable(tf.random_normal([1, 15])),                              \n",
    "    'l3': tf.Variable(tf.random_normal([1, 20])),\n",
    "    'out': tf.Variable(tf.random_normal([1, 3]))\n",
    "}\n",
    "                           \n",
    "    \n",
    "def neural_network(X):\n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(X, weights['l1']), biases['l1']))\n",
    "    layer2 = tf.nn.relu(tf.add(tf.matmul(layer1, weights['l2']), biases['l2']))\n",
    "    layer3 = tf.nn.relu(tf.add(tf.matmul(layer2, weights['l3']), biases['l3']))\n",
    "    out = tf.nn.softmax(tf.nn.relu(tf.add(tf.matmul(layer3, weights['out']), biases['out'])))\n",
    "    return out\n",
    "\n",
    "nn = neural_network(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**3. Thiết lập hàm loss function và phương pháp tối ưu gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 5\n",
    "global_step = tf.Variable(0)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = nn, labels = y))\n",
    "grad_op = tf.reduce_sum(tf.gradients(loss_op, nn)[0])\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op, global_step = global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hàm `tf.nn.softmax_cross_entropy_with_logits_v2(logits, labels)` sẽ tính ra hàm ra giá trị cross entropy giữa 2 phân phối được dự báo từ mạng nơ ron (logits) và phân phối thực tế (labels). Giá trị này càng nhỏ thì giữa 2 phân phối càng sát nhau tức mô hình đưa ra dự báo càng chuẩn xác.\n",
    "Thuật toán gradient descent mà chúng ta sử dụng là AdamOptimizer với learning_rate = 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**4. Fitting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Tính toán mức độ chính xác của model\n",
    "match_pred = tf.equal(tf.cast(tf.argmax(nn, 1), tf.int32), y)\n",
    "acc_op = tf.reduce_mean(tf.cast(match_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hàm `tf.argmax(x, 1)` sẽ tìm ra class có xác xuất lớn nhất trong lớp các class trả về. Đây chính là class được dự báo. Hàm `tf.equal()` sẽ so sánh class dự báo có trùng với class thực tế (ground truth) hay không. acc là tỷ lệ phần trăm dự báo chính xác được tính ra từ trung bình của toàn bộ các kết quả so sánh ở toàn bộ các quan sát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1; grads: 1.862645149230957e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.4291 sec\n",
      "Step 101; grads: 2.60770320892334e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 201; grads: 1.4901161193847656e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 301; grads: 1.862645149230957e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0156 sec\n",
      "Step 401; grads: 1.862645149230957e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0156 sec\n",
      "Step 501; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0060 sec\n",
      "Step 601; grads: 1.862645149230957e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0156 sec\n",
      "Step 701; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0156 sec\n",
      "Step 801; grads: 2.60770320892334e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0156 sec\n",
      "Step 901; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1001; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1101; grads: 2.7939677238464355e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0051 sec\n",
      "Step 1201; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1301; grads: 2.2351741790771484e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1401; grads: 2.421438694000244e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0060 sec\n",
      "Step 1501; grads: 1.4901161193847656e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1601; grads: 2.421438694000244e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1701; grads: 1.4901161193847656e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1801; grads: 2.60770320892334e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Step 1901; grads: 1.862645149230957e-08;Loss value: 1.09861207; Accuracy: 0.3500; time: 0.0000 sec\n",
      "Finished training!\n",
      "Loss value in test: 1.0986; Accuracy in test: 0.2667\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Xây dựng vòng lặp fitting model trên từng batch\n",
    "batch_size = 120 #Kích thước mỗi batch.\n",
    "n_steps = 2000 #Số lượng các lượt cập nhật dữ liệu.\n",
    "print_every = 100 #Khoảng cách lượt cập nhật dữ liệu để in ra kết quả thuật toán.\n",
    "learning_rate = 0.5\n",
    "#Tạo hàm lấy batch tiếp theo. Khi lấy hết đến batch cuối cùng của mẫu sẽ shuffle lại mẫu.\n",
    "def next_batch(X, batch_size, index = 0):\n",
    "    start = index\n",
    "    index += batch_size\n",
    "    if index > len(X['predictor']):\n",
    "        perm = np.arange(len(X['predictor']))\n",
    "        np.random.shuffle(perm)\n",
    "        X['predictor'] = X['predictor'][perm]\n",
    "        X['target'] = X['target'][perm]\n",
    "        start = 0\n",
    "        index = batch_size\n",
    "    end = index\n",
    "    return X['predictor'][start:end], X['target'][start:end], index\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Khởi tạo toàn bộ các biến.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    idx = 0\n",
    "    for step in range(n_steps):\n",
    "        start_time = time.time()\n",
    "        batch_x, batch_y, idx = next_batch(train, batch_size = batch_size, index = idx)\n",
    "        #Thực thi thuật toán gradient descent\n",
    "        sess.run(train_op, feed_dict = {X: batch_x, y: batch_y})\n",
    "        loss = sess.run(loss_op, feed_dict = {X:batch_x, y:batch_y})\n",
    "        acc = sess.run(acc_op, feed_dict = {X:batch_x, y:batch_y})\n",
    "        grad = sess.run(grad_op, feed_dict = {X:batch_x, y:batch_y})\n",
    "        duration = time.time() - start_time\n",
    "        if step % print_every == 0:\n",
    "            print('Step {}; grads: {};Loss value: {:.8f}; Accuracy: {:.4f}; time: {:.4f} sec'.format(sess.run(global_step), grad, loss, acc, duration))\n",
    "#             print(sess.run(weights['l1']))\n",
    "            \n",
    "    print('Finished training!')\n",
    "    print('Loss value in test: {:.4f}; Accuracy in test: {:.4f}'.format(sess.run(loss_op, feed_dict = {X:test['predictor'], y:test['target']}),\n",
    "                                                          sess.run(acc_op, feed_dict = {X:test['predictor'], y:test['target']})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Một lưu ý mà chúng ta không thể quên đó là phải khởi tạo các biến bằng lệnh `tf.global_variables_initializer()` trước khi chạy session để các biến được gán giá trị. Bên dưới là code của toàn bộ quá trình xây dựng mạng nơ ron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-68e35a4c2de5>:22: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request as req\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#set up parameter\n",
    "TRAIN = 'iris_training.csv'\n",
    "TRAIN_URL = 'http://download.tensorflow.org/data/iris_training.csv'\n",
    "TEST = 'iris_testing.csv'\n",
    "TEST_URL = 'http://download.tensorflow.org/data/iris_test.csv'\n",
    "input_shape = 4\n",
    "n_classes = 3\n",
    "\n",
    "def loadfile(filename, link):\n",
    "    if not os.path.exists(filename):\n",
    "        raw = req.urlopen(link).read().decode('utf-8')\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(raw)\n",
    "    data = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=filename,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "    #normalize biến dự báo theo phân phối chuẩn\n",
    "    mu = np.mean(data.data, axis = 0)\n",
    "    sigma = (np.std(data.data, axis=0))\n",
    "    predictor = (data.data - mu) / sigma\n",
    "    \n",
    "    #Chuyển biến mục tiêu sang dạng onehot endcoder\n",
    "#     target = np.eye(len(data.target), n_classes, dtype = np.float32)[data.target]\n",
    "    target = data.target\n",
    "    return {'predictor': predictor, 'target': target}\n",
    "\n",
    "train = loadfile(TRAIN, TRAIN_URL)\n",
    "test = loadfile(TEST, TEST_URL)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, input_shape])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1; grads: -2.9802322387695312e-08;Loss value: 159710.03125000; Accuracy: 0.4083; time: 0.6118 sec\n",
      "Step 101; grads: -3.3527612686157227e-08;Loss value: 1.10983443; Accuracy: 0.3000; time: 0.0080 sec\n",
      "Step 201; grads: 1.30385160446167e-08;Loss value: 1.12865674; Accuracy: 0.3500; time: 0.0080 sec\n",
      "Step 301; grads: -1.862645149230957e-09;Loss value: 1.14147997; Accuracy: 0.3083; time: 0.0080 sec\n",
      "Step 401; grads: 2.2351741790771484e-08;Loss value: 1.15174305; Accuracy: 0.2750; time: 0.0080 sec\n",
      "Step 501; grads: 2.2351741790771484e-08;Loss value: 1.11556244; Accuracy: 0.3500; time: 0.0080 sec\n",
      "Step 601; grads: -4.6566128730773926e-09;Loss value: 1.21996009; Accuracy: 0.2750; time: 0.0080 sec\n",
      "Step 701; grads: 3.725290298461914e-09;Loss value: 1.13091958; Accuracy: 0.2833; time: 0.0080 sec\n",
      "Step 801; grads: 3.259629011154175e-08;Loss value: 1.12134171; Accuracy: 0.3417; time: 0.0080 sec\n",
      "Step 901; grads: 2.514570951461792e-08;Loss value: 1.22984004; Accuracy: 0.3750; time: 0.0040 sec\n",
      "Step 1001; grads: 2.0489096641540527e-08;Loss value: 1.09683442; Accuracy: 0.2917; time: 0.0080 sec\n",
      "Step 1101; grads: -3.725290298461914e-09;Loss value: 1.19309628; Accuracy: 0.3667; time: 0.0080 sec\n",
      "Step 1201; grads: -1.6763806343078613e-08;Loss value: 1.20512998; Accuracy: 0.3250; time: 0.0080 sec\n",
      "Step 1301; grads: 7.450580596923828e-09;Loss value: 1.11130726; Accuracy: 0.2583; time: 0.0080 sec\n",
      "Step 1401; grads: 2.7939677238464355e-09;Loss value: 1.12681019; Accuracy: 0.3500; time: 0.0080 sec\n",
      "Step 1501; grads: -1.862645149230957e-08;Loss value: 1.13170445; Accuracy: 0.3500; time: 0.0080 sec\n",
      "Step 1601; grads: 2.60770320892334e-08;Loss value: 1.16845953; Accuracy: 0.3083; time: 0.0080 sec\n",
      "Step 1701; grads: -2.2351741790771484e-08;Loss value: 1.12944174; Accuracy: 0.3500; time: 0.0080 sec\n",
      "Step 1801; grads: 0.0;Loss value: 1.14309895; Accuracy: 0.3417; time: 0.0080 sec\n",
      "Step 1901; grads: 0.0;Loss value: 1.09930575; Accuracy: 0.3833; time: 0.0080 sec\n",
      "Finished training!\n",
      "Loss value in test: 1.0887; Accuracy in test: 0.3667\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/46264133/weights-and-biases-not-updating-in-tensorflow\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout = 0.7\n",
    "\n",
    "weights = {\n",
    "    'l1': tf.Variable(tf.random_normal([input_shape, 10])),\n",
    "    'l2': tf.Variable(tf.random_normal([10, 15])),                              \n",
    "    'l3': tf.Variable(tf.random_normal([15, 20])),\n",
    "    'out': tf.Variable(tf.random_normal([20, 1]))\n",
    "}\n",
    "\n",
    "\n",
    "biases = {\n",
    "    'l1': tf.Variable(tf.random_normal([1, 10])),\n",
    "    'l2': tf.Variable(tf.random_normal([1, 15])),                              \n",
    "    'l3': tf.Variable(tf.random_normal([1, 20])),\n",
    "    'out': tf.Variable(tf.random_normal([1, 3]))\n",
    "}\n",
    "                           \n",
    "    \n",
    "def neural_network(X):\n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(X, weights['l1']), biases['l1']))\n",
    "    layer2 = tf.nn.relu(tf.add(tf.matmul(layer1, weights['l2']), biases['l2']))\n",
    "    layer3 = tf.nn.relu(tf.add(tf.matmul(layer2, weights['l3']), biases['l3']))\n",
    "    out = tf.nn.dropout(tf.add(tf.matmul(layer3, weights['out']), biases['out']), keep_prob = dropout)\n",
    "    return out\n",
    "\n",
    "nn = neural_network(X)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1\n",
    "global_step = tf.Variable(0)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = nn, labels = y))\n",
    "grad_op = tf.reduce_sum(tf.gradients(loss_op, nn)[0])\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op, global_step = global_step)\n",
    "\n",
    "\n",
    "\n",
    "match_pred = tf.equal(tf.cast(tf.argmax(nn, 1), tf.int32), y)\n",
    "acc_op = tf.reduce_mean(tf.cast(match_pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "#Xây dựng vòng lặp fitting model trên từng batch\n",
    "batch_size = 120 #Kích thước mỗi batch.\n",
    "n_steps = 2000 #Số lượng các lượt cập nhật dữ liệu.\n",
    "print_every = 100 #Khoảng cách lượt cập nhật dữ liệu để in ra kết quả thuật toán.\n",
    "\n",
    "#Tạo hàm lấy batch tiếp theo. Khi lấy hết đến batch cuối cùng của mẫu sẽ shuffle lại mẫu.\n",
    "def next_batch(X, batch_size, index = 0):\n",
    "    start = index\n",
    "    index += batch_size\n",
    "    if index > len(X['predictor']):\n",
    "        perm = np.arange(len(X['predictor']))\n",
    "        np.random.shuffle(perm)\n",
    "        X['predictor'] = X['predictor'][perm]\n",
    "        X['target'] = X['target'][perm]\n",
    "        start = 0\n",
    "        index = batch_size\n",
    "    end = index\n",
    "    return X['predictor'][start:end], X['target'][start:end], index\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Khởi tạo toàn bộ các biến.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    idx = 0\n",
    "    for step in range(n_steps):\n",
    "        start_time = time.time()\n",
    "        batch_x, batch_y, idx = next_batch(train, batch_size = batch_size, index = idx)\n",
    "        #Thực thi thuật toán gradient descent\n",
    "        sess.run(train_op, feed_dict = {X: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        loss = sess.run(loss_op, feed_dict = {X:batch_x, y:batch_y, keep_prob: dropout})\n",
    "        acc = sess.run(acc_op, feed_dict = {X:batch_x, y:batch_y, keep_prob: dropout})\n",
    "        grad = sess.run(grad_op, feed_dict = {X:batch_x, y:batch_y, keep_prob: dropout})\n",
    "        duration = time.time() - start_time\n",
    "        if step % print_every == 0:\n",
    "            print('Step {}; grads: {};Loss value: {:.8f}; Accuracy: {:.4f}; time: {:.4f} sec'.format(sess.run(global_step), grad, loss, acc, duration))\n",
    "#             print(sess.run(weights['l1']))\n",
    "            \n",
    "    print('Finished training!')\n",
    "    print('Loss value in test: {:.4f}; Accuracy in test: {:.4f}'.format(sess.run(loss_op, feed_dict = {X:test['predictor'], y:test['target']}),\n",
    "                                                          sess.run(acc_op, feed_dict = {X:test['predictor'], y:test['target']})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
