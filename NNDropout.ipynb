{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import urllib.request as request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#Khai báo params\n",
    "IRIS_TRAIN = 'iris_training.csv'\n",
    "IRIS_TRAIN_PATH = 'https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/iris_training.csv'\n",
    "IRIS_TEST = 'iris_testing.csv'\n",
    "IRIS_TEST_PATH  = 'https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/iris_testing.csv'\n",
    "COLUMNS = ['SepWid', 'SepLen', 'PenWid', 'PenLen', 'Species']\n",
    "BATCH_SIZE = 100\n",
    "N_STEPS = 2000\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "def get_data(url, filename, is_get_train = True):\n",
    "    if not os.path.exists(filename):\n",
    "        raw = request.urlopen(url).read().decode('utf-8')\n",
    "        with io.open(filename, 'w') as f:\n",
    "            f.write(raw)\n",
    "            \n",
    "    data = pd.read_csv(filename, header = 0, names = COLUMNS, encoding = 'utf-8')\n",
    "    features, labels = data, data.pop('Species')\n",
    "    \n",
    "    #Tạo Class Dataset trong tensorflow\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if is_get_train: \n",
    "        dataset = dataset.shuffle(1000).repeat().batch(batch_size = BATCH_SIZE)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    else:\n",
    "        return dataset.batch(batch_size = BATCH_SIZE)\n",
    "\n",
    "get_data(IRIS_TRAIN_PATH, IRIS_TRAIN, is_get_train = True)\n",
    "get_data(IRIS_TEST_PATH, IRIS_TEST,  is_get_train = False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    test = get_data(IRIS_TEST_PATH, IRIS_TEST, is_get_train = False)\n",
    "    print(sess.run(test.make_one_shot_iterator().get_next()))\n",
    "      \n",
    "\n",
    "def my_model_dropout(features, labels, mode, params):\n",
    "    # 1. Huấn luyện mô hình\n",
    "    # Xây dựng mạng nơ ron\n",
    "    # Khởi tạo input_layer. Hàm input_layer sẽ map dữ liệu đầu vào là features với các estimators thông qua params['features_columns']\n",
    "    nn = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    # Dropout ở input nên có giá trị là 0.7-0.8\n",
    "    nn = tf.nn.dropout(nn, keep_prob = 0.8)\n",
    "    # Xây dựng các hidden layer tiếp theo\n",
    "    for n_units in params['hidden']:\n",
    "        nn = tf.layers.dense(nn, n_units, activation = tf.nn.relu)\n",
    "        # Thêm một layer dropout để giảm overfiting\n",
    "#         nn = tf.nn.dropout(nn, keep_prob = params['dropout'])\n",
    "    # Hàm logits dự báo xác xuất các classes (chính là output layer)\n",
    "    logits = tf.layers.dense(nn, params['n_classes'], activation = tf.nn.softmax)\n",
    "    \n",
    "    # Hàm loss function\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels = labels, \n",
    "        logits = logits)\n",
    "    # Hàm tối ưu hóa kiểm soát thuật toán gradient descent:\n",
    "    # optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "    # Hàm kích hoạt quá trình training mô hình:\n",
    "    train_op = optimizer.minimize(\n",
    "        loss = loss, \n",
    "        global_step = tf.train.get_global_step())\n",
    "    # Estimator trả về \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = mode, \n",
    "            loss = loss, \n",
    "            train_op = train_op)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "    # 2. Đánh giá mô hình\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # Lớp được dự báo \n",
    "        prediction_classes = tf.argmax(logits, 1)\n",
    "        # Mức độ chính xác \n",
    "        accuracy = tf.metrics.accuracy(\n",
    "            labels = labels,\n",
    "            predictions = prediction_classes\n",
    "        )\n",
    "        # Estimator trả về\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = tf.estimator.ModeKeys.EVAL,\n",
    "            loss = loss,\n",
    "            eval_metric_ops = {'accuracy': accuracy}\n",
    "        )\n",
    "    \n",
    "classifier2 = tf.estimator.Estimator(\n",
    "    model_fn = my_model_dropout,\n",
    "    params = {\n",
    "        'feature_columns': my_features, # List tên các feature sử dụng để map dữ liệu từ Dataset với các estimator\n",
    "        'hidden':[10, 20, 10], # Số đơn vị mỗi layer\n",
    "        'n_classes': 3, # Số lượng nhóm cần phân loại\n",
    "        'dropout': 0.5\n",
    "    }\n",
    ")\n",
    "\n",
    "classifier2.train(\n",
    "    input_fn = lambda:get_data(IRIS_TRAIN_PATH, IRIS_TRAIN),\n",
    "    steps = N_STEPS\n",
    ")\n",
    "\n",
    "\n",
    "classifier2.evaluate(\n",
    "    input_fn = lambda:get_data(IRIS_TRAIN_PATH, IRIS_TRAIN, is_get_train = False)\n",
    ")\n",
    "\n",
    "classifier2.evaluate(\n",
    "    input_fn = lambda:get_data(IRIS_TEST_PATH, IRIS_TEST, is_get_train = False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
