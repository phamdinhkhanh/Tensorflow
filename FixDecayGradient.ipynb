{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/46264133/weights-and-biases-not-updating-in-tensorflow\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"E:/workspace_py/datasets/good_bad_buy.csv\")\n",
    "\n",
    "features = data.drop(['index', 'good buy'], axis = 1)\n",
    "lbls = data.drop(['index', 'area', 'bathrooms', 'price', 'sq_price'], axis = 1)\n",
    "\n",
    "features = features[0:20]\n",
    "lbls = lbls[0:20]\n",
    "\n",
    "print(features)\n",
    "print(lbls)\n",
    "n_examples = len(lbls)\n",
    "\n",
    "# Model\n",
    "\n",
    "# Hyper parameters\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "input_data = tf.placeholder('float', [None, 4])\n",
    "labels = tf.placeholder('float', [None, 1])\n",
    "\n",
    "weights = {\n",
    "            'hl1': tf.Variable(tf.random_normal([4, 10])),\n",
    "            'hl2': tf.Variable(tf.random_normal([10, 10])),\n",
    "            'hl3': tf.Variable(tf.random_normal([10, 4])),\n",
    "            'ol': tf.Variable(tf.random_normal([4, 1]))\n",
    "            }\n",
    "\n",
    "biases = {\n",
    "            'hl1': tf.Variable(tf.random_normal([10])),\n",
    "            'hl2': tf.Variable(tf.random_normal([10])),\n",
    "            'hl3': tf.Variable(tf.random_normal([4])),\n",
    "            'ol': tf.Variable(tf.random_normal([1]))\n",
    "            }\n",
    "\n",
    "hl1 = tf.nn.relu(tf.add(tf.matmul(input_data, weights['hl1']), biases['hl1']))\n",
    "hl2 = tf.nn.relu(tf.add(tf.matmul(hl1, weights['hl2']), biases['hl2']))\n",
    "hl3 = tf.nn.relu(tf.add(tf.matmul(hl2, weights['hl3']), biases['hl3']))\n",
    "ol = tf.nn.sigmoid(tf.add(tf.matmul(hl3, weights['ol']), biases['ol']))\n",
    "\n",
    "loss = tf.reduce_mean((labels - ol)**2)\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "iterations = int(n_examples/batch_size)\n",
    "\n",
    "\n",
    "for epoch_no in range(epochs):\n",
    "    ptr = 0\n",
    "    for iteration_no in range(iterations):\n",
    "        epoch_input = features[ptr:ptr+batch_size]\n",
    "        epoch_label = lbls[ptr: ptr+batch_size]\n",
    "        ptr = ptr + batch_size\n",
    "        _, err = sess.run([train, loss], feed_dict={input_data: features, labels: lbls})\n",
    "    print(\"Error at epoch \", epoch_no, \": \", err)\n",
    "\n",
    "print(sess.run(ol, feed_dict={input_data: [[2104, 3, 399900, 190.0665]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables\n",
      "   Variable:0\n",
      "   Variable_1:0\n",
      "   Variable_2:0\n",
      "   Variable_3:0\n",
      "   Variable_4:0\n",
      "   Variable_5:0\n",
      "   Variable_6:0\n",
      "   Variable_7:0\n",
      "-----------------------------------------\n",
      "name MatMul_grad\n",
      "gradient [[ 0.0000000e+00  1.4091998e-04 -2.5916503e-05  7.7960838e-05\n",
      "   3.0659331e-04 -2.0852145e-04  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  2.2595628e-07 -4.1555481e-08  1.2500527e-07\n",
      "   4.9160303e-07 -3.3435103e-07  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  2.4556583e-02 -4.5161862e-03  1.3585383e-02\n",
      "   5.3426668e-02 -3.6336754e-02  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  1.1737194e-05 -2.1585802e-06  6.4933411e-06\n",
      "   2.5536090e-05 -1.7367707e-05  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]]\n",
      "value [[ 0.1976699   0.42406052 -2.3806543  -0.24508852  0.5868657  -0.1204472\n",
      "   0.9411631   0.7618367  -1.182138    0.26041028]\n",
      " [ 1.2803019   0.06524107  0.48258048  0.9780119  -0.74955976  0.13489531\n",
      "   0.61440927  0.45871365 -1.7925887   0.9361711 ]\n",
      " [-0.6599784   0.26124835  0.4966133   0.2967305   1.6622577   0.09080239\n",
      "  -1.4029742  -0.0876968  -0.49567124 -0.9868473 ]\n",
      " [-0.3853749   1.769392   -0.39864546 -0.42752606  0.03916923  0.01487624\n",
      "  -0.44302085 -0.05116237  0.02380138 -0.63226855]]\n",
      "-----------------------------------------\n",
      "name MatMul_1_grad\n",
      "gradient [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.00067928 0.         0.         0.00626117 0.\n",
      "  0.0043432  0.         0.         0.        ]\n",
      " [0.         0.00123969 0.         0.         0.0114266  0.\n",
      "  0.00792633 0.         0.         0.        ]\n",
      " [0.         0.00075786 0.         0.         0.00698546 0.\n",
      "  0.00484563 0.         0.         0.        ]\n",
      " [0.         0.0042772  0.         0.         0.03942422 0.\n",
      "  0.02734754 0.         0.         0.        ]\n",
      " [0.         0.00023141 0.         0.         0.00213297 0.\n",
      "  0.00147959 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "value [[-0.9462605  -0.934874   -0.30437392 -1.574527    1.0294402  -0.12154796\n",
      "   0.6152266   0.47000387 -0.72877955 -0.24397224]\n",
      " [-0.11657943  0.33819258 -0.02974966 -0.96107537  0.5301497  -1.9176484\n",
      "   0.6784928   0.04496211 -0.7940728  -0.4426032 ]\n",
      " [-0.07742772  0.53795886  0.82770973  0.01591465 -0.2736746  -0.41872376\n",
      "   0.03532765 -0.4967846  -0.01708565  2.7246394 ]\n",
      " [ 0.33992735 -0.03440411 -0.9748062   1.3321654  -0.50980675 -0.8455364\n",
      "   1.5677537   2.0054073  -0.59326714 -0.93931496]\n",
      " [-0.89783376  0.06054557 -0.41356617 -0.9437774   1.4004774  -0.50836307\n",
      "   1.2256223  -1.7734627  -0.55496615 -1.6846206 ]\n",
      " [ 3.106281    0.53771836 -1.6245213  -0.5936803  -2.0046973   0.5137084\n",
      "   0.5927351   1.7704332  -1.2008592  -0.5459261 ]\n",
      " [ 1.6266286   1.0789763  -0.46093065 -1.1801932   0.507552   -0.24775116\n",
      "  -2.4545376  -0.69827724  1.2478437  -0.07903301]\n",
      " [ 0.8051042  -0.48279706  0.93508685 -0.695838    1.4835024  -1.0799769\n",
      "   0.08520658 -0.9822917   0.80243075 -1.0479865 ]\n",
      " [ 0.0599132  -0.9926756   0.4659285   0.9216495   0.4627398  -0.18997307\n",
      "   0.05382568 -0.55455303  1.2890805  -0.382505  ]\n",
      " [-0.01214615  0.07266222 -1.2674248  -0.05452468 -1.1315291   0.6602963\n",
      "  -0.46692923 -0.64440066  0.7327924   0.12724365]]\n",
      "-----------------------------------------\n",
      "name MatMul_2_grad\n",
      "gradient [[0.         0.         0.         0.        ]\n",
      " [0.         0.02031582 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.08361043 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.1145798  0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "value [[ 0.82227427  2.6588066   1.6864733  -0.13642187]\n",
      " [-0.80516297  0.06172309 -2.4532344   0.02108373]\n",
      " [-0.36749193 -0.5419344   1.5953252   1.5100816 ]\n",
      " [-1.0052158   1.7213553   1.347724    0.3703052 ]\n",
      " [ 0.5961301   0.56892055 -0.11755177  1.0237895 ]\n",
      " [-0.50090057  0.02995374  0.6731482   1.1503725 ]\n",
      " [-0.57554424  0.39464515  0.33072013 -1.8922268 ]\n",
      " [-0.7032231   0.89705056 -0.47863907  1.2750854 ]\n",
      " [-0.804478    0.12033761 -0.5428672   0.00431295]\n",
      " [ 0.8821923  -0.38605887  0.11855331  1.4753143 ]]\n",
      "-----------------------------------------\n",
      "name MatMul_3_grad\n",
      "gradient [[ 0.        ]\n",
      " [-0.05387856]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "value [[ 0.10056144]\n",
      " [-1.7454062 ]\n",
      " [ 1.6319537 ]\n",
      " [ 2.4005456 ]]\n",
      "-----------------------------------------\n",
      "name Add_grad\n",
      "gradient [ 0.0000000e+00  6.7163214e-08 -1.2351949e-08  3.7156560e-08\n",
      "  1.4612402e-07 -9.9382468e-08  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00]\n",
      "value [-0.49889788  0.1256395  -0.87822473  0.26950362 -0.08196275 -1.2420481\n",
      " -0.50922096 -0.4202046  -0.77593815  0.18014921]\n",
      "-----------------------------------------\n",
      "name Add_1_grad\n",
      "gradient [0.0000000e+00 7.0233166e-09 0.0000000e+00 0.0000000e+00 6.4736064e-08\n",
      " 0.0000000e+00 4.4905693e-08 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "value [ 0.84603703 -0.03302336 -1.4454019  -0.2063181  -0.2612304   0.97664154\n",
      " -0.00411351 -0.52851295 -0.9843198  -2.1638272 ]\n",
      "-----------------------------------------\n",
      "name Add_2_grad\n",
      "gradient [0.0000000e+00 1.1378755e-07 0.0000000e+00 0.0000000e+00]\n",
      "value [ 0.7474027  -0.22461048 -0.95392877 -0.2510684 ]\n",
      "-----------------------------------------\n",
      "name Add_3_grad\n",
      "gradient [ 0.47844505 -0.47844514]\n",
      "value [ 1.3988848 -0.5924133]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'Adam' type=NoOp>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "features = [\n",
    "[2104, 3, 399900, 190.066540],\n",
    "[1600, 3, 329900, 206.187500],\n",
    "[2400, 3, 369000, 153.750000],\n",
    "[1416, 2, 232000, 163.841808],\n",
    "[3000, 4, 539900, 179.966667],\n",
    "[1985, 4, 299900, 151.083123],\n",
    "[1534, 3, 314900, 205.280313],\n",
    "[1427, 3, 198999, 139.452698],\n",
    "[1380, 3, 212000, 153.623188],\n",
    "[1494, 3, 242500, 162.315930],\n",
    "[1940, 4, 239999, 123.710825],\n",
    "[2000, 3, 347000, 173.500000],\n",
    "[1890, 3, 329999, 174.602645],\n",
    "[4478, 5, 699900, 156.297454],\n",
    "[1268, 3, 259900, 204.968454],\n",
    "[2300, 4, 449900, 195.608696],\n",
    "[1320, 2, 299900, 227.196970],\n",
    "[1236, 3, 199900, 161.731392],\n",
    "[2609, 4, 499998, 191.643542],\n",
    "[3031, 4, 599000, 197.624546]]\n",
    "\n",
    "lbls = [1,0,1,0,1,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1]\n",
    "features = np.array(features, dtype=np.float32)\n",
    "lbls = np.array(lbls, dtype=np.int32)\n",
    "\n",
    "n_examples = len(lbls)\n",
    "epochs = 100\n",
    "learning_rate = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "input_data = tf.placeholder('float', [None, 4])\n",
    "labels = tf.placeholder('int32', [None])\n",
    "\n",
    "weights = {\n",
    "            'hl1': tf.Variable(tf.random_normal([4, 10])),\n",
    "            'hl2': tf.Variable(tf.random_normal([10, 10])),\n",
    "            'hl3': tf.Variable(tf.random_normal([10, 4])),\n",
    "            'ol': tf.Variable(tf.random_normal([4, 1]))\n",
    "            }\n",
    "\n",
    "biases = {\n",
    "            'hl1': tf.Variable(tf.random_normal([10])),\n",
    "            'hl2': tf.Variable(tf.random_normal([10])),\n",
    "            'hl3': tf.Variable(tf.random_normal([4])),\n",
    "            # 'ol': tf.Variable(tf.random_normal([1])),\n",
    "            'ol': tf.Variable(tf.random_normal([2]))\n",
    "            }\n",
    "\n",
    "hl1 = tf.nn.relu(tf.add(tf.matmul(input_data, weights['hl1']), biases['hl1']))\n",
    "hl2 = tf.nn.relu(tf.add(tf.matmul(hl1, weights['hl2']), biases['hl2']))\n",
    "hl3 = tf.nn.relu(tf.add(tf.matmul(hl2, weights['hl3']), biases['hl3']))\n",
    "# ol = tf.nn.sigmoid(tf.add(tf.matmul(hl3, weights['ol']), biases['ol']))\n",
    "logits = tf.add(tf.matmul(hl3, weights['ol']), biases['ol'])\n",
    "\n",
    "# ol = tf.Print(ol, [tf.reduce_sum(weights['hl1'])])\n",
    "# loss = tf.reduce_mean((labels - ol)**2)\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "# loss = tf.reduce_mean((labels - ol)**2)\n",
    "loss = tf.reduce_mean(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "iterations = int(n_examples/batch_size)\n",
    "\n",
    "def debug_minimize(optimizer, loss, sess):\n",
    "    from tensorflow.python.ops import variables\n",
    "    from tensorflow.python.framework import ops\n",
    "    # get all varibles\n",
    "    var_list = (variables.trainable_variables() + ops.get_collection(ops.GraphKeys.TRAINABLE_RESOURCE_VARIABLES))\n",
    "    print('variables')\n",
    "    for v in var_list:\n",
    "        print('  ', v.name)\n",
    "    # get all gradients\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "    zipped_val = sess.run(grads_and_vars, {input_data: features, labels: lbls})\n",
    "\n",
    "    for rsl, tensor in zip(zipped_val, grads_and_vars):\n",
    "        print('-----------------------------------------')\n",
    "        print('name', tensor[0].name.replace('/tuple/control_dependency_1:0', '').replace('gradients/', ''))\n",
    "        print('gradient', rsl[0])\n",
    "        print('value', rsl[1])\n",
    "    return train_op\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "debug_minimize(optimizer, loss, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant(np.arange(12), shape = [3, 4], dtype = tf.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
