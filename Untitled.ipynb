{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ef7b34fe3091>:120: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000289CA07EC50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.08933225 0.1119273  0.10757308 0.1039223  0.08789473 0.10350856\n",
      "  0.10269367 0.09683584 0.10544613 0.09086622]\n",
      " [0.11184823 0.10597798 0.10692956 0.10922697 0.07426232 0.09859978\n",
      "  0.09172621 0.09860528 0.10599611 0.09682761]\n",
      " [0.09137035 0.09851266 0.104982   0.10894646 0.07702237 0.09769309\n",
      "  0.10932585 0.10061727 0.10073075 0.11079921]\n",
      " [0.09172273 0.1083644  0.10530216 0.09559192 0.07826544 0.09990523\n",
      "  0.09625405 0.10488816 0.10060599 0.11909993]\n",
      " [0.09073739 0.10427567 0.10357049 0.09531637 0.09581412 0.10839415\n",
      "  0.10785668 0.09465794 0.09743918 0.10193806]\n",
      " [0.09494594 0.10578095 0.10404985 0.0973689  0.08736909 0.11630102\n",
      "  0.09273721 0.09786226 0.09814058 0.1054443 ]\n",
      " [0.09521861 0.10236184 0.08777148 0.10781803 0.09041322 0.10654402\n",
      "  0.10371269 0.08943466 0.10672414 0.11000122]\n",
      " [0.08666755 0.10787008 0.10033268 0.0983592  0.09356542 0.10760511\n",
      "  0.10266472 0.1014972  0.0964039  0.10503417]\n",
      " [0.08685645 0.09923089 0.10625065 0.10361075 0.0800771  0.10625074\n",
      "  0.10565716 0.10328936 0.10448024 0.10429674]\n",
      " [0.08080219 0.11821734 0.10687266 0.106024   0.08613468 0.1059878\n",
      "  0.10066605 0.10640726 0.09086326 0.09802484]\n",
      " [0.09288682 0.10225802 0.09555824 0.09914591 0.084571   0.12133949\n",
      "  0.09392169 0.10433424 0.10094879 0.10503567]\n",
      " [0.09060917 0.09359349 0.10499369 0.09748047 0.07828401 0.10852288\n",
      "  0.11490532 0.09254378 0.11120722 0.10785992]\n",
      " [0.08503869 0.10699528 0.1024823  0.09944733 0.0733624  0.10082465\n",
      "  0.11251873 0.0981031  0.1121126  0.10911481]\n",
      " [0.09115314 0.09422229 0.09707557 0.09817741 0.08544061 0.1048392\n",
      "  0.11704172 0.10083506 0.10572816 0.1054868 ]\n",
      " [0.08841433 0.09494877 0.10265279 0.11104534 0.08227362 0.1089379\n",
      "  0.10183647 0.10690183 0.10727096 0.09571812]\n",
      " [0.08191326 0.11171719 0.08935404 0.10499021 0.08483118 0.09613752\n",
      "  0.10300394 0.11344264 0.11482126 0.09978872]\n",
      " [0.09225857 0.11046464 0.08735564 0.11008407 0.08153319 0.12737714\n",
      "  0.08552656 0.09398384 0.09691449 0.11450193]\n",
      " [0.08770503 0.1046653  0.10512607 0.10604325 0.0872602  0.11736125\n",
      "  0.09531032 0.10733526 0.09555701 0.09363619]\n",
      " [0.08271491 0.10822283 0.10876738 0.10984107 0.08384367 0.09181554\n",
      "  0.11159571 0.10602283 0.09831666 0.09885941]\n",
      " [0.08049386 0.0983867  0.1001768  0.10311618 0.0739217  0.10192075\n",
      "  0.1152183  0.10229108 0.12445588 0.10001873]\n",
      " [0.08266275 0.09744642 0.09719771 0.09155596 0.10193341 0.10979754\n",
      "  0.10197462 0.10454596 0.10538341 0.10750221]\n",
      " [0.08870359 0.09110907 0.10430238 0.10353296 0.0795385  0.10698949\n",
      "  0.11329304 0.09408237 0.10574219 0.11270642]\n",
      " [0.08926852 0.09848988 0.10750512 0.09936506 0.08450764 0.11260712\n",
      "  0.09074477 0.10597912 0.10228939 0.10924335]\n",
      " [0.09235396 0.11741085 0.09885114 0.09007321 0.08563619 0.09704377\n",
      "  0.10668368 0.09933147 0.09445042 0.11816522]\n",
      " [0.09680247 0.10539549 0.09893701 0.0980434  0.07970089 0.11812562\n",
      "  0.09620867 0.09933876 0.10258637 0.10486121]\n",
      " [0.09610043 0.12209534 0.09924755 0.09952816 0.07587189 0.09901001\n",
      "  0.10894755 0.10898372 0.10531703 0.08489835]\n",
      " [0.09119418 0.09809282 0.09919446 0.09577136 0.0919415  0.1129075\n",
      "  0.1050503  0.11099961 0.09955733 0.09529091]\n",
      " [0.10047571 0.09713279 0.10935909 0.09975851 0.07723075 0.09343252\n",
      "  0.12102094 0.09335308 0.10948553 0.09875104]\n",
      " [0.09920625 0.11870324 0.09199923 0.09671918 0.08905315 0.09902025\n",
      "  0.09975193 0.10920594 0.09457979 0.10176106]\n",
      " [0.07644492 0.09514531 0.09826458 0.11567308 0.07162732 0.11328205\n",
      "  0.11272317 0.10712784 0.10364073 0.10607102]\n",
      " [0.08888226 0.10505892 0.1241223  0.08599345 0.09093132 0.11524813\n",
      "  0.09448734 0.09783985 0.10013271 0.09730379]\n",
      " [0.09282801 0.10200848 0.10127215 0.10064542 0.08787803 0.10605226\n",
      "  0.10588685 0.09905297 0.10561749 0.09875833]\n",
      " [0.07555571 0.10845978 0.11085062 0.1019504  0.07963932 0.11295935\n",
      "  0.10520992 0.10770556 0.09738557 0.10028373]\n",
      " [0.08941062 0.10415267 0.09950935 0.09907728 0.08222052 0.12670222\n",
      "  0.09519211 0.09556299 0.08773138 0.12044088]\n",
      " [0.07591634 0.10806172 0.10204995 0.10963335 0.0730038  0.09504325\n",
      "  0.1056952  0.11648027 0.1052979  0.10881822]\n",
      " [0.09992982 0.10005365 0.09973387 0.09604564 0.09001669 0.10706186\n",
      "  0.09995904 0.09547365 0.10734741 0.10437844]\n",
      " [0.08980545 0.10051619 0.10975862 0.11069807 0.08642082 0.10243142\n",
      "  0.10883319 0.0912004  0.10322305 0.09711289]\n",
      " [0.09340122 0.10584358 0.09489204 0.10876851 0.08390162 0.0833334\n",
      "  0.10852711 0.10100587 0.11879869 0.10152793]\n",
      " [0.0840163  0.11384456 0.09427347 0.09917091 0.07789362 0.10320609\n",
      "  0.10320957 0.10741595 0.10093059 0.11603895]\n",
      " [0.09341422 0.09357135 0.10142485 0.09858449 0.07302411 0.1065916\n",
      "  0.11309611 0.09985319 0.10561457 0.11482554]\n",
      " [0.08499449 0.11682007 0.10012406 0.09995382 0.07740267 0.10240618\n",
      "  0.09817113 0.11291904 0.09733099 0.10987753]\n",
      " [0.0861328  0.11014327 0.10885237 0.11157395 0.07968613 0.09940169\n",
      "  0.10630558 0.08686567 0.11007889 0.1009597 ]\n",
      " [0.09471062 0.10694008 0.09848134 0.09905894 0.08419268 0.11048447\n",
      "  0.09799464 0.09671838 0.10439562 0.10702318]\n",
      " [0.0811735  0.11540668 0.09381893 0.11267548 0.09276921 0.10310403\n",
      "  0.10786277 0.08812045 0.104896   0.100173  ]\n",
      " [0.09291331 0.10835093 0.11288736 0.10872968 0.07822577 0.09231314\n",
      "  0.0974052  0.11225273 0.10472041 0.09220142]\n",
      " [0.09686789 0.10365824 0.1016059  0.10440139 0.0875287  0.11401927\n",
      "  0.09345432 0.10382684 0.09656198 0.09807548]\n",
      " [0.10445715 0.10993934 0.09856862 0.10038307 0.07838643 0.10280178\n",
      "  0.12223998 0.09273134 0.09836309 0.09212919]\n",
      " [0.08727501 0.10783304 0.11274146 0.09789016 0.08956732 0.09405519\n",
      "  0.11108116 0.09881009 0.1021108  0.09863582]\n",
      " [0.09925801 0.09302671 0.09126265 0.10334522 0.08939128 0.11538786\n",
      "  0.11372954 0.09522823 0.10479822 0.09457232]\n",
      " [0.09970062 0.10710174 0.0877878  0.09818891 0.0884193  0.0984432\n",
      "  0.09961526 0.1024413  0.10325903 0.11504284]\n",
      " [0.09412404 0.1156384  0.10495136 0.09200306 0.09672394 0.1040078\n",
      "  0.08608521 0.0955733  0.10662414 0.10426879]\n",
      " [0.09250931 0.09935839 0.09846672 0.10173418 0.08958575 0.1015683\n",
      "  0.10759643 0.09479648 0.10236084 0.11202367]\n",
      " [0.09296315 0.09607141 0.10765854 0.09840934 0.09017678 0.10145172\n",
      "  0.10760157 0.09197197 0.11537185 0.0983237 ]\n",
      " [0.08665814 0.11095454 0.08345771 0.09956072 0.08523616 0.10846893\n",
      "  0.12036868 0.0892776  0.10837016 0.10764728]\n",
      " [0.09726071 0.10638013 0.10779663 0.0961242  0.0792437  0.11490274\n",
      "  0.10124249 0.09704172 0.09312719 0.10688046]\n",
      " [0.08993093 0.09990205 0.10678294 0.1056453  0.0857887  0.10514465\n",
      "  0.10634883 0.09797616 0.09163046 0.11085004]\n",
      " [0.0964769  0.10622799 0.10815281 0.090367   0.09497193 0.10656601\n",
      "  0.0977125  0.09583496 0.10053562 0.10315435]\n",
      " [0.08275758 0.13055125 0.10624857 0.1052976  0.07349991 0.0928538\n",
      "  0.10533744 0.09408287 0.10701495 0.10235605]\n",
      " [0.09651405 0.11054221 0.10624198 0.09242681 0.08779301 0.10651474\n",
      "  0.10726573 0.09967488 0.09402675 0.0989999 ]\n",
      " [0.09920842 0.09711303 0.10389722 0.10601921 0.08788721 0.10152072\n",
      "  0.10320481 0.10744281 0.09789272 0.09581389]\n",
      " [0.08923353 0.10230985 0.09509803 0.10768799 0.07992657 0.10840515\n",
      "  0.1056338  0.08991296 0.10366598 0.1181261 ]\n",
      " [0.09421727 0.09767855 0.1010873  0.09650138 0.09380229 0.10496516\n",
      "  0.09798631 0.09810494 0.1112533  0.10440347]\n",
      " [0.08549262 0.11348907 0.10345156 0.1041162  0.09381397 0.11995576\n",
      "  0.08310767 0.09941636 0.08737159 0.10978521]\n",
      " [0.09657732 0.11040798 0.10725256 0.11001809 0.0755638  0.10508004\n",
      "  0.10015993 0.08908416 0.09268014 0.11317604]\n",
      " [0.08445951 0.10130271 0.1105439  0.10891194 0.07685238 0.10900691\n",
      "  0.09479751 0.10755098 0.09859627 0.10797778]\n",
      " [0.09978983 0.10590603 0.08808864 0.10527615 0.08784017 0.10354291\n",
      "  0.11320335 0.09997698 0.10336571 0.09301019]\n",
      " [0.08236765 0.11588274 0.11341732 0.10144014 0.07781857 0.11275806\n",
      "  0.10077223 0.09404462 0.08984233 0.11165629]\n",
      " [0.09012485 0.11870217 0.10281254 0.10046244 0.07982208 0.10319249\n",
      "  0.09867385 0.10043523 0.10333727 0.10243702]\n",
      " [0.09015728 0.10864328 0.09561498 0.09926737 0.09512139 0.10518352\n",
      "  0.09489197 0.09462015 0.11418036 0.10231962]\n",
      " [0.09060225 0.11450358 0.10094047 0.11115905 0.08212642 0.09878294\n",
      "  0.10170057 0.09509489 0.09916561 0.10592422]\n",
      " [0.09463924 0.11047018 0.09524794 0.11404032 0.07887454 0.09635174\n",
      "  0.10054471 0.11120556 0.09784971 0.1007761 ]\n",
      " [0.08390651 0.10679147 0.10258421 0.10355593 0.0828007  0.1074193\n",
      "  0.09327143 0.10616423 0.10499275 0.10851348]\n",
      " [0.08395673 0.10101381 0.10874226 0.1017027  0.08614358 0.10726545\n",
      "  0.10314023 0.10492731 0.11084235 0.0922655 ]\n",
      " [0.09021188 0.10775382 0.10575019 0.09633287 0.09154864 0.09523021\n",
      "  0.10551845 0.1069365  0.09899114 0.10172632]\n",
      " [0.08670384 0.09588356 0.10211581 0.11825146 0.08781756 0.10778687\n",
      "  0.10897575 0.09450864 0.10454454 0.09341194]\n",
      " [0.0981975  0.10571785 0.11379559 0.08823147 0.08523879 0.10499976\n",
      "  0.10324612 0.09372088 0.09453233 0.11231975]\n",
      " [0.09813914 0.1076044  0.10749134 0.09075947 0.07944423 0.11294354\n",
      "  0.09665807 0.11386009 0.09213338 0.10096642]\n",
      " [0.08307219 0.09643802 0.10170214 0.10007774 0.09779184 0.11435771\n",
      "  0.09893468 0.09691604 0.10653556 0.10417421]\n",
      " [0.08833324 0.09640108 0.10225368 0.1073181  0.0836386  0.1085635\n",
      "  0.10004354 0.11066741 0.09845472 0.10432608]\n",
      " [0.09709433 0.11275071 0.08117024 0.12765032 0.07100009 0.09508277\n",
      "  0.09626987 0.09664539 0.10966095 0.11267529]\n",
      " [0.08955015 0.1074111  0.10955684 0.10383794 0.08034094 0.11036104\n",
      "  0.09520291 0.10433958 0.09831052 0.10108894]\n",
      " [0.08942563 0.1150453  0.09669066 0.10708597 0.08686958 0.09557668\n",
      "  0.10365343 0.09832872 0.10597787 0.10134611]\n",
      " [0.07597592 0.09843709 0.1082367  0.11061883 0.07639547 0.11498135\n",
      "  0.10438447 0.10420331 0.09104909 0.11571777]\n",
      " [0.09299044 0.10110636 0.10865176 0.09395873 0.09690564 0.1043539\n",
      "  0.11130728 0.09940046 0.09886943 0.09245606]\n",
      " [0.10531256 0.10700185 0.10219952 0.09321865 0.08759581 0.10881691\n",
      "  0.09282266 0.09249171 0.1093936  0.10114671]\n",
      " [0.10327421 0.11971355 0.0886097  0.09784651 0.08452671 0.10065041\n",
      "  0.11237076 0.09695612 0.10113426 0.09491786]\n",
      " [0.09923647 0.09943223 0.10188829 0.11822148 0.07488268 0.08945707\n",
      "  0.10732539 0.10657712 0.09287083 0.11010851]\n",
      " [0.09799121 0.10652687 0.08531074 0.11236031 0.07413737 0.10423525\n",
      "  0.10287034 0.10186484 0.10217299 0.1125301 ]\n",
      " [0.08490573 0.09546717 0.11670729 0.09857128 0.09144764 0.11594389\n",
      "  0.10071544 0.09771854 0.0961667  0.1023563 ]\n",
      " [0.09254146 0.10443394 0.10390271 0.09320782 0.08222373 0.10827121\n",
      "  0.09880047 0.10339885 0.10997985 0.10323998]\n",
      " [0.10279915 0.10026491 0.11573715 0.09455059 0.08354928 0.10588995\n",
      "  0.0973632  0.10232621 0.09527222 0.10224738]\n",
      " [0.0967733  0.10628341 0.10830984 0.09554441 0.075659   0.10145415\n",
      "  0.11735798 0.09563907 0.09497919 0.1079996 ]\n",
      " [0.09908974 0.11757916 0.09578968 0.09507751 0.08866461 0.10131248\n",
      "  0.10264391 0.10599834 0.09036009 0.10348447]\n",
      " [0.09300654 0.1007578  0.1016915  0.10316486 0.08109588 0.10608704\n",
      "  0.1045877  0.09862725 0.10726391 0.10371752]\n",
      " [0.09433644 0.1005097  0.09933963 0.09032965 0.08662797 0.10236562\n",
      "  0.1084251  0.10586718 0.10055503 0.11164366]\n",
      " [0.09414273 0.10594632 0.12295104 0.0943241  0.07916927 0.11185689\n",
      "  0.10745857 0.08527643 0.08961701 0.10925758]\n",
      " [0.08820777 0.10184631 0.09338903 0.11648719 0.08824132 0.11973169\n",
      "  0.08569575 0.11087947 0.08927438 0.10624711]\n",
      " [0.08721659 0.09218819 0.1012336  0.10918619 0.08269583 0.11477783\n",
      "  0.10704602 0.10291852 0.09339197 0.10934525]\n",
      " [0.0983947  0.10251969 0.10536305 0.10214859 0.07709449 0.10257074\n",
      "  0.10251781 0.09650636 0.10694542 0.1059391 ]\n",
      " [0.09687757 0.11382893 0.10425518 0.11083061 0.07984367 0.10613646\n",
      "  0.10889267 0.09146596 0.09420864 0.09366029]]\n",
      "INFO:tensorflow:loss = 2.2990174, step = 1\n",
      "INFO:tensorflow:probabilities = [[0.09406688 0.11527745 0.09570801 0.13379396 0.07145922 0.09746331\n",
      "  0.11008951 0.09933442 0.08595774 0.0968494 ]\n",
      " [0.08613946 0.10023514 0.09716103 0.09015714 0.09839403 0.10251027\n",
      "  0.11056238 0.10487874 0.10624757 0.10371435]\n",
      " [0.0988175  0.10524917 0.10163876 0.10316236 0.08651613 0.10060903\n",
      "  0.10436291 0.10674445 0.09426574 0.09863399]\n",
      " [0.09667699 0.10087077 0.09790406 0.11609499 0.07603183 0.09740887\n",
      "  0.09872278 0.11267024 0.1022723  0.10134714]\n",
      " [0.09278312 0.10167609 0.09914746 0.1070717  0.08256894 0.09749214\n",
      "  0.12435031 0.09522269 0.10107437 0.09861325]\n",
      " [0.09306257 0.1089902  0.11240967 0.08913751 0.08831515 0.11515228\n",
      "  0.09715891 0.10051078 0.09606775 0.09919515]\n",
      " [0.0931142  0.1013179  0.09671917 0.09807608 0.09002991 0.10756175\n",
      "  0.11139338 0.09801386 0.11232203 0.09145172]\n",
      " [0.08907246 0.11972934 0.09944592 0.10947242 0.08607448 0.10770909\n",
      "  0.0950058  0.1009255  0.09277382 0.09979129]\n",
      " [0.08627713 0.09753756 0.09691887 0.10456593 0.09194981 0.11214316\n",
      "  0.1032345  0.10322496 0.09932954 0.10481849]\n",
      " [0.08899146 0.09871119 0.09749761 0.10736775 0.08750623 0.10156242\n",
      "  0.10288175 0.1012683  0.10807128 0.10614206]\n",
      " [0.08596551 0.09774509 0.10497112 0.10675583 0.09536594 0.09636129\n",
      "  0.10358371 0.1071652  0.1066076  0.09547874]\n",
      " [0.08812517 0.10985924 0.09754848 0.09687703 0.09261248 0.11057514\n",
      "  0.10310725 0.10049058 0.09703436 0.10377029]\n",
      " [0.08069311 0.08811961 0.09247721 0.10582717 0.09164496 0.1019256\n",
      "  0.11455848 0.10689792 0.10722978 0.11062615]\n",
      " [0.09970121 0.10614856 0.10004182 0.09446391 0.08432167 0.10109034\n",
      "  0.09944032 0.09933372 0.10182513 0.11363337]\n",
      " [0.09249543 0.10349783 0.10297842 0.10484406 0.08912247 0.10186044\n",
      "  0.09578805 0.10856128 0.10272312 0.09812895]\n",
      " [0.08950581 0.10185203 0.1088042  0.09677514 0.09807698 0.11227076\n",
      "  0.10576284 0.09336614 0.09017727 0.10340876]\n",
      " [0.09361023 0.11534803 0.10196685 0.09054469 0.07870861 0.09320484\n",
      "  0.10680313 0.10523156 0.11290048 0.10168154]\n",
      " [0.08173261 0.11370389 0.10293653 0.10910717 0.07776444 0.1160712\n",
      "  0.0999728  0.10734849 0.08967636 0.1016865 ]\n",
      " [0.10145812 0.11317625 0.09327662 0.10364047 0.07695243 0.09429401\n",
      "  0.11968113 0.10302808 0.09127904 0.10321382]\n",
      " [0.09192495 0.11204927 0.0968842  0.1021109  0.08052199 0.10339322\n",
      "  0.10140375 0.09875797 0.10295359 0.11000013]\n",
      " [0.08371443 0.09880301 0.10053473 0.1132004  0.08449122 0.1024151\n",
      "  0.1000813  0.09911504 0.10515054 0.1124943 ]\n",
      " [0.10505366 0.12945107 0.09269044 0.09993717 0.08047736 0.09726314\n",
      "  0.10008854 0.11600398 0.08216896 0.09686568]\n",
      " [0.09145414 0.10292877 0.10322121 0.09755738 0.09085257 0.0967162\n",
      "  0.104141   0.10189598 0.10178381 0.10944889]\n",
      " [0.10423881 0.10949523 0.10216379 0.0896251  0.08114033 0.09794024\n",
      "  0.10834901 0.09953952 0.10046925 0.10703874]\n",
      " [0.09472835 0.09817196 0.09762462 0.10526381 0.08416291 0.11700833\n",
      "  0.11207692 0.10027992 0.09679388 0.09388934]\n",
      " [0.10542289 0.11221135 0.09896346 0.0986898  0.07764417 0.10875154\n",
      "  0.11787639 0.0862732  0.08473165 0.10943561]\n",
      " [0.09685075 0.10232271 0.09598503 0.1174517  0.0803678  0.1027655\n",
      "  0.10107744 0.09542176 0.10506948 0.10268779]\n",
      " [0.08544943 0.09263334 0.10430945 0.1099756  0.09002429 0.11051913\n",
      "  0.10955383 0.09830306 0.0919093  0.10732265]\n",
      " [0.10166751 0.10390506 0.11138251 0.09888595 0.07278853 0.08667563\n",
      "  0.10896712 0.10550953 0.10516909 0.10504907]\n",
      " [0.0992619  0.10484976 0.10272422 0.09985325 0.09001525 0.10374975\n",
      "  0.10393122 0.09509556 0.09082872 0.10969037]\n",
      " [0.08783203 0.10620774 0.09766965 0.11587904 0.08575168 0.09252083\n",
      "  0.0947933  0.09995881 0.11056875 0.10881833]\n",
      " [0.08664408 0.09928726 0.09908414 0.0944416  0.08466788 0.11349422\n",
      "  0.08972807 0.10323314 0.1190424  0.11037714]\n",
      " [0.08472078 0.10168398 0.10637054 0.0977624  0.10088434 0.09636489\n",
      "  0.10570033 0.10094263 0.09912832 0.10644184]\n",
      " [0.08514308 0.11163155 0.10883956 0.1014774  0.08540805 0.09750289\n",
      "  0.11225696 0.11480155 0.0916279  0.09131116]\n",
      " [0.09415555 0.0960561  0.09615088 0.08236629 0.0893407  0.11055996\n",
      "  0.09982789 0.10792874 0.10954154 0.11407237]\n",
      " [0.10263009 0.10071214 0.1157649  0.10276641 0.08426587 0.1030848\n",
      "  0.0948357  0.09499774 0.10429878 0.09664364]\n",
      " [0.09080861 0.1018275  0.09968251 0.09605398 0.09389669 0.11329916\n",
      "  0.09511904 0.1020891  0.10198945 0.10523404]\n",
      " [0.09906655 0.10025077 0.10163572 0.10297356 0.08871014 0.10266968\n",
      "  0.09978984 0.10650021 0.10245202 0.09595165]\n",
      " [0.09126019 0.11905099 0.09478773 0.12722927 0.07803466 0.09333884\n",
      "  0.09068335 0.10919482 0.09936656 0.09705361]\n",
      " [0.08985163 0.11084341 0.09869046 0.10531039 0.0759892  0.11014229\n",
      "  0.09804291 0.10588638 0.10260046 0.10264298]\n",
      " [0.08941871 0.10579274 0.10004155 0.10119173 0.08699051 0.09261224\n",
      "  0.11752772 0.10005514 0.09759238 0.10877729]\n",
      " [0.09603127 0.11762097 0.10309435 0.09405977 0.09406442 0.0981765\n",
      "  0.09681772 0.0937793  0.10093516 0.10542054]\n",
      " [0.09493933 0.10430939 0.1015593  0.09761792 0.09395705 0.10460839\n",
      "  0.10363498 0.10151777 0.10265818 0.09519771]\n",
      " [0.09938101 0.09844489 0.10843073 0.09095995 0.08601817 0.11187951\n",
      "  0.09475098 0.09268796 0.10966539 0.1077814 ]\n",
      " [0.08551621 0.09517641 0.10961683 0.09832913 0.08634273 0.11303643\n",
      "  0.09478053 0.10475977 0.10275197 0.10969   ]\n",
      " [0.09434348 0.09401297 0.10286626 0.12077106 0.07898092 0.09477782\n",
      "  0.10520771 0.09727877 0.09480507 0.116956  ]\n",
      " [0.08576139 0.11877352 0.10179564 0.10156657 0.0856337  0.10120364\n",
      "  0.09473407 0.1002539  0.10274029 0.10753725]\n",
      " [0.10886765 0.09748942 0.09599718 0.09480289 0.09262791 0.10643529\n",
      "  0.09321718 0.10974403 0.10152371 0.09929462]\n",
      " [0.10304511 0.1077662  0.10360489 0.09995446 0.07833393 0.11019196\n",
      "  0.09688599 0.09537961 0.09789199 0.10694582]\n",
      " [0.08796769 0.12448945 0.09278706 0.11187684 0.08321796 0.09396783\n",
      "  0.09585831 0.10202038 0.09901324 0.10880133]\n",
      " [0.0928766  0.10519432 0.10928906 0.11059174 0.08223224 0.10079261\n",
      "  0.10525624 0.09157785 0.09533281 0.10685658]\n",
      " [0.07991859 0.10050333 0.11103295 0.1005773  0.0867126  0.11571717\n",
      "  0.12129854 0.09306134 0.09058566 0.10059254]\n",
      " [0.08340918 0.10610661 0.10441427 0.10323246 0.07897911 0.11340187\n",
      "  0.11169146 0.09606273 0.09933267 0.10336968]\n",
      " [0.08305944 0.10169344 0.10706115 0.09522052 0.09148291 0.11315928\n",
      "  0.10400105 0.09857391 0.09630733 0.10944103]\n",
      " [0.09212329 0.11250506 0.10273903 0.09517227 0.08602457 0.10237426\n",
      "  0.10483437 0.09615249 0.10129977 0.10677477]\n",
      " [0.0840865  0.11584184 0.08877233 0.11048812 0.07856499 0.08975425\n",
      "  0.115562   0.09757058 0.11415961 0.10519973]\n",
      " [0.09032939 0.10224395 0.10726511 0.09310604 0.08573924 0.09578893\n",
      "  0.11071654 0.0982831  0.10286881 0.11365888]\n",
      " [0.09893093 0.0963533  0.1103973  0.10061222 0.08737247 0.10370769\n",
      "  0.09881171 0.10190053 0.09679475 0.10511901]\n",
      " [0.09057208 0.11067573 0.11799219 0.09735643 0.07812697 0.09280601\n",
      "  0.11408517 0.0866741  0.10897524 0.10273612]\n",
      " [0.09592624 0.12217645 0.09667594 0.08876066 0.08691364 0.1005763\n",
      "  0.10439189 0.10150334 0.09578513 0.10729037]\n",
      " [0.09030306 0.09555908 0.1058782  0.10614911 0.09725703 0.09756211\n",
      "  0.1112528  0.09712662 0.10791133 0.09100062]\n",
      " [0.07933632 0.10207205 0.10207365 0.09524181 0.08837871 0.10284571\n",
      "  0.11913497 0.09709135 0.10585739 0.10796811]\n",
      " [0.08226355 0.10176597 0.10828938 0.10593057 0.08005057 0.09346338\n",
      "  0.11860266 0.10948002 0.10203956 0.09811431]\n",
      " [0.09158956 0.11141552 0.09934223 0.09875441 0.0840196  0.08407313\n",
      "  0.11189188 0.09429206 0.10615111 0.11847048]\n",
      " [0.09294178 0.11413471 0.10053448 0.10634921 0.07933103 0.10189726\n",
      "  0.10257426 0.09853717 0.10516299 0.09853713]\n",
      " [0.09244431 0.10117145 0.10152187 0.10115159 0.08154972 0.10711963\n",
      "  0.10547992 0.1053622  0.10138387 0.10281541]\n",
      " [0.09414772 0.10568658 0.10032652 0.09946188 0.08778823 0.09279776\n",
      "  0.10229114 0.09850314 0.11316981 0.10582724]\n",
      " [0.09715792 0.08640375 0.09921154 0.1165347  0.07921727 0.10466003\n",
      "  0.10426756 0.10388276 0.09870778 0.10995672]\n",
      " [0.09813125 0.11425218 0.09884865 0.09320596 0.08385622 0.10155546\n",
      "  0.10234281 0.10086813 0.10241732 0.10452195]\n",
      " [0.1010048  0.10079505 0.09782104 0.09960122 0.07487484 0.10091159\n",
      "  0.11137003 0.09465276 0.10151339 0.11745522]\n",
      " [0.09440045 0.1000426  0.10173226 0.10139851 0.08025287 0.10454597\n",
      "  0.10535911 0.10165256 0.10212504 0.10849065]\n",
      " [0.09415276 0.11671744 0.09691056 0.10614762 0.0755356  0.09908967\n",
      "  0.09660067 0.11108454 0.0985229  0.10523827]\n",
      " [0.08867899 0.10932936 0.09474183 0.1018826  0.08438683 0.08043652\n",
      "  0.11001921 0.10817569 0.11035096 0.11199802]\n",
      " [0.08980875 0.10425185 0.11366709 0.10921926 0.08708725 0.09927387\n",
      "  0.09960776 0.10042313 0.10876767 0.08789341]\n",
      " [0.09440813 0.11577264 0.09735472 0.10287371 0.07526755 0.10582126\n",
      "  0.11022258 0.08938681 0.10206639 0.10682613]\n",
      " [0.0872663  0.10392297 0.09588164 0.09480233 0.07908031 0.10296158\n",
      "  0.11457916 0.108505   0.11362784 0.09937289]\n",
      " [0.09582017 0.09787491 0.10816696 0.10851633 0.08666752 0.10667197\n",
      "  0.10150528 0.10169509 0.09325302 0.09982869]\n",
      " [0.09313633 0.09481426 0.10910462 0.10529983 0.09234522 0.10656522\n",
      "  0.09050307 0.10701    0.09684786 0.10437357]\n",
      " [0.08809347 0.0989847  0.10125091 0.12071452 0.07898304 0.11045381\n",
      "  0.10597254 0.10545672 0.09533725 0.09475309]\n",
      " [0.09129615 0.10534397 0.09826017 0.09931848 0.08823527 0.09610204\n",
      "  0.11102641 0.09409729 0.1099314  0.10638872]\n",
      " [0.09325771 0.11461928 0.09915114 0.10296958 0.07899983 0.10094215\n",
      "  0.09889309 0.10923458 0.09481863 0.10711399]\n",
      " [0.09642705 0.09785887 0.10776488 0.10853453 0.07788829 0.10413418\n",
      "  0.11796891 0.09795889 0.09238473 0.09907964]\n",
      " [0.09222154 0.1077169  0.09750059 0.09860785 0.08662161 0.11954878\n",
      "  0.10051828 0.09976172 0.10600889 0.09149375]\n",
      " [0.10938321 0.10479945 0.08713593 0.1113994  0.07520394 0.09949576\n",
      "  0.09944926 0.1097357  0.1026757  0.10072162]\n",
      " [0.08858768 0.10561316 0.11173078 0.08930134 0.09055555 0.11011181\n",
      "  0.09977686 0.10784079 0.09292316 0.10355887]\n",
      " [0.09169955 0.10196029 0.10927631 0.10109138 0.08612946 0.10879061\n",
      "  0.10804532 0.09517168 0.09508764 0.10274768]\n",
      " [0.0946445  0.09961754 0.09328752 0.11044226 0.08286645 0.1043062\n",
      "  0.11770558 0.09507878 0.09579588 0.1062553 ]\n",
      " [0.0915563  0.10201809 0.10755101 0.10962401 0.0896416  0.10401124\n",
      "  0.10521086 0.09051376 0.09969113 0.10018201]\n",
      " [0.08660635 0.09061914 0.10387237 0.10445008 0.0818432  0.09727091\n",
      "  0.1164676  0.10729114 0.10217685 0.10940234]\n",
      " [0.09427522 0.11438613 0.09410573 0.10433779 0.08515888 0.11734881\n",
      "  0.09765671 0.09718616 0.08983785 0.10570674]\n",
      " [0.09208794 0.10709193 0.09643354 0.11529771 0.08565047 0.10956343\n",
      "  0.09170348 0.10400435 0.09788495 0.10028213]\n",
      " [0.09434886 0.09886291 0.10592216 0.09903789 0.08569029 0.11479074\n",
      "  0.10365794 0.08806474 0.10637066 0.10325381]\n",
      " [0.08624133 0.10926073 0.10427634 0.11372378 0.08891789 0.10296521\n",
      "  0.10411242 0.08959739 0.09501395 0.10589099]\n",
      " [0.10719275 0.09534898 0.10812449 0.10130286 0.08208615 0.10563681\n",
      "  0.10414419 0.09730773 0.09496521 0.10389081]\n",
      " [0.08911209 0.09973232 0.10445489 0.10547245 0.08565782 0.09808702\n",
      "  0.11018528 0.10831384 0.10561921 0.09336504]\n",
      " [0.07262451 0.09210587 0.11341225 0.10993908 0.10115915 0.10337001\n",
      "  0.11664191 0.10026602 0.09010976 0.10037141]\n",
      " [0.09144423 0.09669404 0.09714624 0.10273706 0.08419656 0.1139833\n",
      "  0.10244942 0.10137919 0.09922172 0.11074824]\n",
      " [0.07448602 0.08943829 0.1147477  0.10483954 0.0866448  0.11279474\n",
      "  0.10718144 0.10433377 0.09567319 0.10986059]\n",
      " [0.09086111 0.09904728 0.09415447 0.09907797 0.08921784 0.10875936\n",
      "  0.10961004 0.09999177 0.09584714 0.11343312]\n",
      " [0.09379569 0.11385334 0.105498   0.09717003 0.0863245  0.11215872\n",
      "  0.10671961 0.09689566 0.0968091  0.09077535]] (137.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.34574\n",
      "INFO:tensorflow:probabilities = [[0.08440562 0.10772665 0.0960632  0.1014432  0.07972393 0.10116988\n",
      "  0.11797961 0.11018353 0.10527594 0.09602839]\n",
      " [0.10599896 0.09670114 0.10692149 0.10732572 0.07052341 0.10098719\n",
      "  0.1038366  0.10284834 0.09865841 0.10619868]\n",
      " [0.09626933 0.10273311 0.10591476 0.109371   0.07842778 0.10186491\n",
      "  0.10826496 0.09770874 0.09295178 0.10649352]\n",
      " [0.08755044 0.10594443 0.09377376 0.09802668 0.09355682 0.10883474\n",
      "  0.10686918 0.10399847 0.08846943 0.11297606]\n",
      " [0.09131901 0.09599242 0.09817746 0.09435722 0.08372454 0.11816864\n",
      "  0.09770103 0.10566498 0.09988248 0.11501217]\n",
      " [0.08961342 0.09887912 0.09914836 0.10533344 0.09031033 0.11403279\n",
      "  0.09310897 0.10431053 0.09327754 0.1119855 ]\n",
      " [0.09464002 0.0879106  0.09550308 0.12452365 0.08093116 0.09755132\n",
      "  0.09585684 0.10669915 0.10347451 0.11290972]\n",
      " [0.09046917 0.1060112  0.10841261 0.09419856 0.09659641 0.09426861\n",
      "  0.10336517 0.10325126 0.10848799 0.09493908]\n",
      " [0.09449881 0.10857581 0.09793074 0.09492628 0.08422556 0.09682383\n",
      "  0.10594033 0.1052948  0.11174503 0.10003871]\n",
      " [0.09539498 0.09262484 0.08108234 0.12854074 0.09780934 0.10390825\n",
      "  0.10506351 0.09601143 0.09453515 0.10502945]\n",
      " [0.09751267 0.09025975 0.09917075 0.11316113 0.07947313 0.10564651\n",
      "  0.11635979 0.10544664 0.10028598 0.09268361]\n",
      " [0.08740405 0.09703388 0.10195462 0.1046714  0.08847986 0.10703089\n",
      "  0.09820289 0.09438478 0.09963413 0.12120349]\n",
      " [0.08473698 0.10093009 0.10330178 0.10396919 0.08069501 0.11394452\n",
      "  0.10398801 0.096021   0.10406876 0.10834473]\n",
      " [0.08899412 0.10641155 0.11105931 0.10978413 0.07723003 0.105515\n",
      "  0.11306267 0.08854072 0.10738876 0.09201372]\n",
      " [0.09388226 0.10166404 0.10471611 0.10127756 0.09527747 0.10895286\n",
      "  0.09916473 0.09839933 0.10433456 0.09233113]\n",
      " [0.08892372 0.10434793 0.11100154 0.10235658 0.08724783 0.1006833\n",
      "  0.10343332 0.0969945  0.10272232 0.10228889]\n",
      " [0.10264195 0.09831471 0.09677679 0.11101119 0.08795258 0.08964442\n",
      "  0.09263202 0.1093107  0.11122175 0.10049391]\n",
      " [0.10108974 0.10169681 0.09584432 0.10775381 0.0850609  0.10404279\n",
      "  0.1032171  0.09632228 0.09649851 0.10847371]\n",
      " [0.09899586 0.1041702  0.10530355 0.08935071 0.08491532 0.10663617\n",
      "  0.10160043 0.10578244 0.10200715 0.10123824]\n",
      " [0.08623218 0.12118391 0.09761562 0.10502867 0.07925238 0.09052136\n",
      "  0.11750776 0.1017682  0.10489886 0.09599105]\n",
      " [0.08933201 0.10599717 0.10702763 0.11246017 0.07844875 0.09355909\n",
      "  0.11063102 0.10623251 0.09545296 0.10085872]\n",
      " [0.09547353 0.10190283 0.10547141 0.11158302 0.08037863 0.10652968\n",
      "  0.09717464 0.11487655 0.08492919 0.10168052]\n",
      " [0.09056394 0.11964969 0.10455502 0.0992043  0.07867369 0.09004506\n",
      "  0.10061368 0.08587503 0.10121179 0.12960786]\n",
      " [0.0813486  0.11066967 0.1112652  0.09913357 0.07109389 0.10459271\n",
      "  0.10925132 0.09265866 0.11068182 0.10930464]\n",
      " [0.08378088 0.09236829 0.09874281 0.0966868  0.08990865 0.11562444\n",
      "  0.09475403 0.10820609 0.11170806 0.10821991]\n",
      " [0.10211018 0.10664444 0.09863982 0.0954469  0.09026243 0.10264072\n",
      "  0.09330579 0.09635804 0.10761056 0.1069811 ]\n",
      " [0.10188098 0.10820014 0.10506441 0.10045863 0.09213486 0.10210226\n",
      "  0.10054182 0.09919801 0.09302368 0.09739528]\n",
      " [0.09025924 0.10567247 0.11864785 0.10559781 0.08653551 0.1060885\n",
      "  0.09270959 0.09248087 0.10166316 0.1003451 ]\n",
      " [0.10309636 0.0984479  0.08553278 0.09869588 0.1024571  0.09685566\n",
      "  0.11262126 0.09124025 0.10308483 0.10796801]\n",
      " [0.08975711 0.09122249 0.11352245 0.11008245 0.08416854 0.08802921\n",
      "  0.10797678 0.11276645 0.0989662  0.10350832]\n",
      " [0.09062096 0.10636398 0.10669611 0.10377944 0.08495849 0.10238072\n",
      "  0.09114787 0.09940541 0.10597734 0.10866968]\n",
      " [0.09132315 0.09606745 0.10293198 0.08985256 0.08807307 0.12474983\n",
      "  0.10217895 0.10754812 0.10167359 0.09560135]\n",
      " [0.08871439 0.09640203 0.10416289 0.11641401 0.09040934 0.09834961\n",
      "  0.10393067 0.09278415 0.10387797 0.10495495]\n",
      " [0.08389048 0.11689237 0.11061845 0.10302405 0.07574815 0.10811143\n",
      "  0.10052128 0.09847213 0.09704057 0.1056811 ]\n",
      " [0.1004141  0.10789946 0.09652608 0.10135179 0.0781754  0.09285928\n",
      "  0.11643836 0.09515315 0.10178042 0.10940205]\n",
      " [0.0938858  0.10181538 0.11161072 0.10160819 0.09326511 0.0961658\n",
      "  0.1130774  0.0993543  0.09238532 0.09683204]\n",
      " [0.09191383 0.08521634 0.10911093 0.10983142 0.09357784 0.1020697\n",
      "  0.09927969 0.09621841 0.09889764 0.11388417]\n",
      " [0.08727051 0.11121969 0.09983148 0.10200154 0.08176234 0.09144448\n",
      "  0.1278961  0.09385271 0.10548394 0.09923718]\n",
      " [0.09720879 0.10213424 0.09612758 0.10566951 0.09124538 0.10634501\n",
      "  0.09498093 0.10203234 0.09139106 0.1128652 ]\n",
      " [0.09402242 0.09457787 0.1006489  0.11384445 0.07316074 0.09078386\n",
      "  0.11046492 0.11401748 0.11227737 0.09620198]\n",
      " [0.08298671 0.09357708 0.11001882 0.11183102 0.08991228 0.09933665\n",
      "  0.10600976 0.09687434 0.09650444 0.1129488 ]\n",
      " [0.09887329 0.10618813 0.09392504 0.11589837 0.08198186 0.09398578\n",
      "  0.10872538 0.10586761 0.09611448 0.09844013]\n",
      " [0.08847281 0.08746207 0.10022774 0.11157761 0.08815479 0.10228177\n",
      "  0.11613461 0.09996197 0.10479744 0.10092929]\n",
      " [0.09107521 0.09482846 0.10356237 0.10186078 0.07533722 0.09983692\n",
      "  0.10857737 0.10144051 0.09623345 0.12724765]\n",
      " [0.09701213 0.10137548 0.08750764 0.11294743 0.07259905 0.10575625\n",
      "  0.09536514 0.12871578 0.09612724 0.1025938 ]\n",
      " [0.08834916 0.11593585 0.09935533 0.11269682 0.08240809 0.11798719\n",
      "  0.08433775 0.09807003 0.09843189 0.10242786]\n",
      " [0.10253785 0.10136762 0.0949669  0.10555699 0.08016233 0.1080963\n",
      "  0.10470552 0.10448505 0.08832617 0.10979524]\n",
      " [0.10432615 0.10001489 0.09983731 0.10374342 0.07401245 0.10577799\n",
      "  0.10968208 0.11512144 0.08657189 0.10091237]\n",
      " [0.0928498  0.09650514 0.10208297 0.10803402 0.08234328 0.11183861\n",
      "  0.10541069 0.09449304 0.1064431  0.0999993 ]\n",
      " [0.1060764  0.10862261 0.094993   0.11506332 0.08029414 0.09898844\n",
      "  0.09298934 0.10893197 0.098859   0.09518175]\n",
      " [0.09717584 0.10701613 0.10363993 0.10260163 0.08310348 0.11085106\n",
      "  0.1027729  0.09350976 0.09426743 0.10506197]\n",
      " [0.0922123  0.09685835 0.0969298  0.10372736 0.07515986 0.11980543\n",
      "  0.09689241 0.10751498 0.09353393 0.11736561]\n",
      " [0.0987968  0.09368247 0.11119363 0.10368247 0.08540283 0.10060633\n",
      "  0.10091569 0.10928381 0.09303356 0.10340251]\n",
      " [0.09186064 0.10314089 0.10816497 0.0960186  0.08337009 0.10421955\n",
      "  0.10297283 0.09840643 0.10597617 0.10586994]\n",
      " [0.09784529 0.09986997 0.09434537 0.11572582 0.08758425 0.10942524\n",
      "  0.10381877 0.09280138 0.08879884 0.10978515]\n",
      " [0.09027144 0.10097217 0.08650753 0.10121185 0.09053065 0.10477181\n",
      "  0.10242376 0.10578789 0.10717028 0.11035263]\n",
      " [0.09837252 0.10632854 0.10946688 0.09587987 0.08383885 0.10345125\n",
      "  0.10476898 0.08971024 0.10044895 0.10773393]\n",
      " [0.08809348 0.10561979 0.10211573 0.10883975 0.0838097  0.10033402\n",
      "  0.11155929 0.08597272 0.09552976 0.1181258 ]\n",
      " [0.08937621 0.09489197 0.10555445 0.10319865 0.09205262 0.10864381\n",
      "  0.09418103 0.09599552 0.1158551  0.10025064]\n",
      " [0.09906138 0.091088   0.095446   0.09746398 0.08643519 0.09376621\n",
      "  0.10541985 0.10288783 0.11856265 0.10986893]\n",
      " [0.09290098 0.08865438 0.10471613 0.10649793 0.07864155 0.11763132\n",
      "  0.10762282 0.10042348 0.09409871 0.10881275]\n",
      " [0.09630515 0.0981373  0.09744116 0.11727062 0.07226919 0.10263018\n",
      "  0.10216338 0.10181595 0.08788983 0.12407724]\n",
      " [0.09209668 0.09962026 0.11370446 0.09315677 0.08190374 0.11118478\n",
      "  0.11113996 0.08831277 0.09069183 0.11818873]\n",
      " [0.08547843 0.11353162 0.10135756 0.11236686 0.08451351 0.08523646\n",
      "  0.10667203 0.10155857 0.10455643 0.10472845]\n",
      " [0.10184665 0.10473105 0.10574967 0.10452498 0.08154659 0.09878727\n",
      "  0.09299158 0.11044891 0.09971692 0.09965645]\n",
      " [0.08985897 0.09429806 0.09915653 0.10256843 0.08754766 0.10449763\n",
      "  0.11209518 0.09962923 0.10495387 0.10539445]\n",
      " [0.09721635 0.09846795 0.10242102 0.10182228 0.09562765 0.10081889\n",
      "  0.09612542 0.10716702 0.09733353 0.10299988]\n",
      " [0.10126656 0.09667765 0.09688935 0.09773403 0.09033309 0.0947722\n",
      "  0.09508183 0.1020609  0.11052726 0.11465711]\n",
      " [0.08996695 0.0950366  0.09387844 0.1011432  0.09377488 0.11306256\n",
      "  0.10958349 0.09852774 0.10358276 0.10144342]\n",
      " [0.08853101 0.10364305 0.10596427 0.10272575 0.08248888 0.10812476\n",
      "  0.11029108 0.10248464 0.09967236 0.09607421]\n",
      " [0.09013151 0.10356425 0.11348714 0.09848458 0.08490939 0.10479093\n",
      "  0.11478365 0.0946295  0.09056454 0.10465449]\n",
      " [0.08618604 0.09839843 0.09974242 0.09362324 0.09670416 0.09672774\n",
      "  0.10745048 0.10201751 0.10926804 0.10988201]\n",
      " [0.09644586 0.09128422 0.1004003  0.11192028 0.08873782 0.09737337\n",
      "  0.10684764 0.10334945 0.1001836  0.10345747]\n",
      " [0.09849864 0.09605543 0.10041495 0.12834272 0.06345387 0.12261809\n",
      "  0.0942205  0.09489232 0.09215786 0.10934572]\n",
      " [0.08311778 0.09232482 0.12353063 0.09820514 0.08516677 0.12283631\n",
      "  0.10835102 0.08990396 0.09031592 0.10624765]\n",
      " [0.09093447 0.09857734 0.10306007 0.10284924 0.09241219 0.10787165\n",
      "  0.10749412 0.10215468 0.10461523 0.09003103]\n",
      " [0.09533441 0.10607161 0.09716345 0.11882754 0.08979382 0.09164025\n",
      "  0.11439841 0.08880512 0.09999989 0.09796549]\n",
      " [0.09950072 0.10563966 0.10352127 0.11453796 0.07912952 0.09625518\n",
      "  0.09893169 0.10170365 0.11297744 0.08780304]\n",
      " [0.09196439 0.1108393  0.09044988 0.11257499 0.08420263 0.10723615\n",
      "  0.09749755 0.10825058 0.09714677 0.09983785]\n",
      " [0.09137049 0.10802576 0.10516017 0.10202779 0.07964875 0.10422052\n",
      "  0.09806538 0.09810284 0.10517795 0.10820034]\n",
      " [0.08820007 0.11937024 0.1051989  0.10106912 0.08302281 0.10092182\n",
      "  0.09392007 0.09530593 0.10540842 0.10758254]\n",
      " [0.0865555  0.10843581 0.10839172 0.09909233 0.08792886 0.09798904\n",
      "  0.10803732 0.08999777 0.11219999 0.10137162]\n",
      " [0.10776197 0.10957214 0.09006443 0.12458275 0.08186682 0.09265856\n",
      "  0.09485415 0.10765941 0.09241279 0.0985671 ]\n",
      " [0.10063105 0.10574921 0.11367597 0.09743482 0.07878389 0.07666142\n",
      "  0.09495769 0.11178095 0.10562404 0.11470094]\n",
      " [0.08977744 0.08499382 0.1115363  0.09883296 0.09328289 0.11018821\n",
      "  0.09755852 0.10371167 0.10495448 0.10516367]\n",
      " [0.10091402 0.09311134 0.10475722 0.11023927 0.09617274 0.101888\n",
      "  0.10744518 0.10225884 0.09785642 0.08535706]\n",
      " [0.09294993 0.11383814 0.09750961 0.10761941 0.07294886 0.10195322\n",
      "  0.09492892 0.09238169 0.11222321 0.11364706]\n",
      " [0.08601948 0.09820141 0.0973885  0.11525487 0.07585903 0.10288208\n",
      "  0.10996042 0.10162899 0.11376586 0.09903946]\n",
      " [0.09074902 0.11305149 0.10691323 0.10191354 0.08165172 0.09047279\n",
      "  0.10235997 0.09481198 0.10362109 0.11445516]\n",
      " [0.09180295 0.08993097 0.10898253 0.09834252 0.10784641 0.10267794\n",
      "  0.09764312 0.09814315 0.10468594 0.09994441]\n",
      " [0.09356209 0.09331919 0.09945256 0.10391474 0.08826526 0.11113285\n",
      "  0.0990814  0.09587308 0.10756454 0.10783434]\n",
      " [0.1022137  0.10771262 0.09808967 0.10387439 0.08834118 0.10375705\n",
      "  0.10225106 0.0961676  0.09211259 0.10548002]\n",
      " [0.09213632 0.09573691 0.11108799 0.10169081 0.08438498 0.10794975\n",
      "  0.10403605 0.09520543 0.09436622 0.11340562]\n",
      " [0.09447806 0.08099866 0.10466629 0.10966781 0.08742967 0.11219931\n",
      "  0.09416976 0.10662804 0.09959436 0.11016808]\n",
      " [0.09389514 0.098422   0.10838107 0.11046585 0.07251893 0.09837562\n",
      "  0.10440762 0.10548342 0.11315791 0.09489246]\n",
      " [0.09355218 0.10361971 0.09539289 0.1049966  0.09129692 0.11308526\n",
      "  0.09188244 0.09481835 0.10570321 0.10565248]\n",
      " [0.10598485 0.10059076 0.09297811 0.11976082 0.09908929 0.09549697\n",
      "  0.09397563 0.10310653 0.09981018 0.08920685]\n",
      " [0.08665118 0.1069113  0.10300483 0.10481998 0.08561756 0.11209448\n",
      "  0.1005484  0.09289107 0.10301956 0.10444155]\n",
      " [0.0861095  0.09935708 0.1027576  0.09582002 0.0943892  0.11233158\n",
      "  0.1034972  0.09802838 0.09454644 0.11316299]\n",
      " [0.10092296 0.09853363 0.09796983 0.11589847 0.0828584  0.08717766\n",
      "  0.113168   0.10431917 0.10512969 0.09402212]] (151.579 sec)\n",
      "INFO:tensorflow:loss = 2.2965004, step = 101 (289.303 sec)\n",
      "INFO:tensorflow:probabilities = [[0.08541349 0.10029936 0.11040737 0.09570759 0.09229105 0.09667654\n",
      "  0.10862783 0.1030663  0.10657167 0.10093873]\n",
      " [0.09688783 0.09753428 0.09991381 0.10004261 0.10257539 0.10897117\n",
      "  0.08782592 0.10123215 0.10096481 0.10405209]\n",
      " [0.08568509 0.1028646  0.09504279 0.10036114 0.09870546 0.0983792\n",
      "  0.11730026 0.093398   0.09885385 0.1094096 ]\n",
      " [0.09171278 0.10404197 0.10019666 0.10204994 0.07743328 0.10086703\n",
      "  0.11233827 0.11294536 0.09752822 0.10088649]\n",
      " [0.08588957 0.11613889 0.10339242 0.10979497 0.08721115 0.08891547\n",
      "  0.11221807 0.09516035 0.09955227 0.1017268 ]\n",
      " [0.10081296 0.09473891 0.11050518 0.11032187 0.08351846 0.10961603\n",
      "  0.09924136 0.08951718 0.1032524  0.09847573]\n",
      " [0.0929027  0.1121283  0.1062415  0.10275936 0.09018733 0.10037412\n",
      "  0.10728157 0.09706582 0.10308494 0.08797437]\n",
      " [0.08574371 0.10068034 0.10801048 0.10372018 0.09227774 0.10528444\n",
      "  0.09714451 0.10446645 0.10174074 0.10093147]\n",
      " [0.09565382 0.1084116  0.12048407 0.09029562 0.08205625 0.09751595\n",
      "  0.10741742 0.09004519 0.09464594 0.1134742 ]\n",
      " [0.11059172 0.09319112 0.10239971 0.0957809  0.09634466 0.09703914\n",
      "  0.09910835 0.10003866 0.09295212 0.11255359]\n",
      " [0.09038285 0.09332237 0.1122328  0.10000163 0.09294409 0.10976943\n",
      "  0.10286988 0.09852608 0.09811326 0.10183762]\n",
      " [0.11397134 0.08814353 0.10789532 0.11180669 0.08757827 0.09824717\n",
      "  0.1000164  0.08884128 0.10116878 0.1023312 ]\n",
      " [0.09330175 0.10050323 0.12317835 0.08825962 0.07525281 0.10685254\n",
      "  0.1042642  0.09958072 0.0971922  0.11161463]\n",
      " [0.09250174 0.09825335 0.09878563 0.11094941 0.07901699 0.09719756\n",
      "  0.09559368 0.1059342  0.11229522 0.10947229]\n",
      " [0.10433584 0.09801225 0.10769996 0.10915662 0.07836834 0.09686815\n",
      "  0.11422978 0.08899238 0.10416187 0.09817481]\n",
      " [0.09698141 0.09872384 0.10406924 0.10743468 0.09049302 0.09121312\n",
      "  0.10188291 0.10015652 0.10443814 0.10460715]\n",
      " [0.09132366 0.10934763 0.10824849 0.1038451  0.08163239 0.09826078\n",
      "  0.11819991 0.09924187 0.09948302 0.09041722]\n",
      " [0.08983058 0.09235082 0.09847406 0.10204297 0.09204235 0.10324556\n",
      "  0.10229827 0.09913213 0.11131867 0.10926453]\n",
      " [0.08029421 0.10644601 0.10153301 0.10575689 0.08265508 0.09514298\n",
      "  0.1252735  0.09632558 0.10651089 0.10006188]\n",
      " [0.09281611 0.09417563 0.12150265 0.10069962 0.08826911 0.10754569\n",
      "  0.10758532 0.08973292 0.10104775 0.09662519]\n",
      " [0.11022478 0.09720268 0.10072377 0.10852357 0.08095268 0.1036107\n",
      "  0.09973944 0.10039689 0.09110621 0.10751934]\n",
      " [0.10564484 0.09026409 0.10457572 0.10525345 0.08678221 0.09531078\n",
      "  0.1029687  0.11365782 0.09336463 0.10217772]\n",
      " [0.09035191 0.09948339 0.0942386  0.09505082 0.0801629  0.10194924\n",
      "  0.11121142 0.10933602 0.10893749 0.10927832]\n",
      " [0.09051128 0.0948474  0.08980076 0.09764298 0.08946935 0.092995\n",
      "  0.13123916 0.0926834  0.11406195 0.10674872]\n",
      " [0.09026559 0.09315257 0.10303727 0.09121519 0.09973082 0.10375422\n",
      "  0.10354197 0.10772044 0.10533035 0.10225157]\n",
      " [0.09691305 0.09610201 0.10717455 0.0917603  0.08860223 0.10530847\n",
      "  0.11083739 0.09917141 0.09729502 0.10683554]\n",
      " [0.09733231 0.10987831 0.09966804 0.09483313 0.07906181 0.11029099\n",
      "  0.09760121 0.10219527 0.10104514 0.10809384]\n",
      " [0.08704944 0.10329501 0.10204612 0.11567836 0.08589028 0.11069493\n",
      "  0.09604815 0.09522258 0.11126344 0.09281166]\n",
      " [0.09688773 0.10374546 0.09858264 0.11100207 0.08866131 0.10536841\n",
      "  0.0983859  0.09950412 0.09968385 0.09817854]\n",
      " [0.09903719 0.11342609 0.10763899 0.09405126 0.09270779 0.09878265\n",
      "  0.10296337 0.09510002 0.09390407 0.10238858]\n",
      " [0.09332447 0.1023636  0.10534447 0.10912199 0.07882023 0.11408696\n",
      "  0.0877547  0.10132514 0.10025708 0.10760136]\n",
      " [0.10175099 0.10056086 0.11302398 0.09879179 0.0899026  0.09894802\n",
      "  0.10130195 0.08214641 0.11459183 0.09898143]\n",
      " [0.09896755 0.10496664 0.09937289 0.12013965 0.06888768 0.08696662\n",
      "  0.10531801 0.10615861 0.10730423 0.10191818]\n",
      " [0.09074149 0.10684648 0.10139699 0.11623645 0.08408941 0.10030355\n",
      "  0.10328473 0.11025836 0.09682634 0.0900161 ]\n",
      " [0.0966585  0.10325883 0.10957676 0.09968486 0.08439685 0.10188109\n",
      "  0.10500643 0.09841831 0.11047617 0.09064215]\n",
      " [0.09046104 0.09535883 0.10200541 0.10279039 0.08895957 0.10783222\n",
      "  0.10027209 0.1030817  0.10779909 0.10143968]\n",
      " [0.09380733 0.10556249 0.09030192 0.13647196 0.08574554 0.09268481\n",
      "  0.09976391 0.10244782 0.09400534 0.09920893]\n",
      " [0.09654722 0.10232519 0.10161407 0.10165516 0.09076957 0.0914204\n",
      "  0.10790339 0.10474328 0.10837277 0.09464896]\n",
      " [0.09324373 0.10990408 0.10375899 0.09085605 0.08195834 0.11356083\n",
      "  0.10491845 0.10865132 0.0991183  0.09402991]\n",
      " [0.08034322 0.1011759  0.09542796 0.09887717 0.09384423 0.11117186\n",
      "  0.10301234 0.10875258 0.10803196 0.09936283]\n",
      " [0.09308747 0.10565411 0.10774258 0.10753677 0.08547852 0.08465508\n",
      "  0.12240902 0.09816542 0.0985041  0.09676692]\n",
      " [0.10408413 0.10069491 0.10926012 0.0988741  0.08524074 0.10194799\n",
      "  0.10374349 0.09662645 0.09443691 0.10509113]\n",
      " [0.10485227 0.10980779 0.10049132 0.10104493 0.08534295 0.10074227\n",
      "  0.08953599 0.10960088 0.09122153 0.10736018]\n",
      " [0.09577656 0.09728032 0.11164549 0.10496589 0.08783514 0.1101777\n",
      "  0.11131189 0.08761377 0.08976916 0.10362412]\n",
      " [0.09131478 0.11394957 0.09827732 0.11663646 0.08241196 0.09461501\n",
      "  0.09882893 0.1100588  0.09639697 0.0975103 ]\n",
      " [0.08493412 0.09891406 0.10101066 0.1013056  0.09331726 0.09996923\n",
      "  0.11095607 0.09844856 0.11109161 0.10005271]\n",
      " [0.09447929 0.11263068 0.10430234 0.10404982 0.08726013 0.10330231\n",
      "  0.09867951 0.09532192 0.10104347 0.09893049]\n",
      " [0.0988624  0.09093384 0.09265865 0.1081781  0.08475512 0.11313889\n",
      "  0.10737426 0.10206233 0.09153736 0.11049912]\n",
      " [0.10376974 0.10215957 0.11366611 0.1040732  0.07981821 0.10262409\n",
      "  0.10652218 0.10041206 0.09653588 0.09041898]\n",
      " [0.09390158 0.09138753 0.10222233 0.10092711 0.0944817  0.11851019\n",
      "  0.10203589 0.10522992 0.09626314 0.09504067]\n",
      " [0.09699012 0.09268322 0.11008362 0.10278709 0.07578447 0.10336868\n",
      "  0.10662968 0.10188854 0.1034606  0.10632406]\n",
      " [0.09033535 0.10345296 0.10334235 0.10894684 0.08263859 0.10711283\n",
      "  0.10425676 0.10283384 0.09310848 0.10397203]\n",
      " [0.09026612 0.09945166 0.11034927 0.09854338 0.08641259 0.09724959\n",
      "  0.10588715 0.11835689 0.09751726 0.0959661 ]\n",
      " [0.09396771 0.08697534 0.10302902 0.10645831 0.08338851 0.10527781\n",
      "  0.09623151 0.11372624 0.1028215  0.10812409]\n",
      " [0.08761095 0.09737512 0.10778929 0.09315867 0.08847192 0.08712913\n",
      "  0.13980265 0.09712549 0.10308589 0.09845091]\n",
      " [0.08006862 0.09556153 0.10219147 0.10741366 0.0961647  0.09291553\n",
      "  0.09798022 0.09565485 0.09869429 0.13335511]\n",
      " [0.10254385 0.10019314 0.10631578 0.10155667 0.07742893 0.08610535\n",
      "  0.10517923 0.10870972 0.10065644 0.11131087]\n",
      " [0.09827226 0.10318849 0.09213161 0.10723616 0.07762989 0.10364684\n",
      "  0.10753186 0.10121619 0.10571609 0.10343054]\n",
      " [0.09260912 0.08949813 0.11230799 0.10263009 0.09512829 0.09606016\n",
      "  0.11606577 0.10469913 0.10033887 0.0906624 ]\n",
      " [0.0945772  0.09672214 0.10236383 0.10719231 0.08841082 0.10768446\n",
      "  0.10327015 0.08808049 0.10628553 0.10541314]\n",
      " [0.09029201 0.1074255  0.11430155 0.09441034 0.08200271 0.09924783\n",
      "  0.10187298 0.09337737 0.10377382 0.11329591]\n",
      " [0.08196039 0.09494127 0.12408849 0.09631736 0.0880881  0.08889084\n",
      "  0.11307726 0.10801029 0.09276491 0.11186112]\n",
      " [0.09976486 0.10331044 0.1084346  0.11170584 0.08423493 0.09141506\n",
      "  0.09317973 0.10722609 0.1041835  0.09654503]\n",
      " [0.10826759 0.09499791 0.08348817 0.11201218 0.07421856 0.10554039\n",
      "  0.10021781 0.1056936  0.10051212 0.11505162]\n",
      " [0.09175415 0.10726303 0.09663998 0.122159   0.08439291 0.08946711\n",
      "  0.09884743 0.10862789 0.11940242 0.08144608]\n",
      " [0.08951812 0.10437255 0.11081211 0.09716672 0.08941837 0.10167436\n",
      "  0.10182293 0.103802   0.09501505 0.10639779]\n",
      " [0.10244817 0.09705888 0.09695968 0.11340101 0.08113539 0.11650416\n",
      "  0.08017887 0.09449352 0.11678588 0.10103443]\n",
      " [0.10354166 0.1052002  0.10258576 0.11438786 0.08551881 0.10082783\n",
      "  0.08847655 0.11379839 0.09376859 0.09189435]\n",
      " [0.09632007 0.08899043 0.10053787 0.09871669 0.10300178 0.10669246\n",
      "  0.09412859 0.11498357 0.08560158 0.11102699]\n",
      " [0.1012072  0.11406101 0.08934462 0.11779942 0.08032835 0.09380858\n",
      "  0.09128436 0.10889775 0.11196673 0.09130204]\n",
      " [0.08490709 0.10595799 0.0969739  0.10270803 0.08549517 0.1108432\n",
      "  0.10868451 0.1009836  0.10241755 0.10102891]\n",
      " [0.1066744  0.10702249 0.10522068 0.10843766 0.07304559 0.09061638\n",
      "  0.09750997 0.1024882  0.11477825 0.09420641]\n",
      " [0.09595761 0.11019642 0.09987607 0.0950994  0.08840486 0.10125469\n",
      "  0.10450191 0.10260507 0.09404793 0.10805598]\n",
      " [0.08912319 0.09847371 0.09946568 0.10365179 0.0774389  0.09644426\n",
      "  0.11174919 0.10792864 0.11189444 0.10383021]\n",
      " [0.0926559  0.09636918 0.09856568 0.10195395 0.0933062  0.09632514\n",
      "  0.11065959 0.10392197 0.09829901 0.10794333]\n",
      " [0.09896062 0.10521315 0.09000727 0.09903557 0.09740531 0.10670458\n",
      "  0.088805   0.10403199 0.10090633 0.10893019]\n",
      " [0.1003923  0.08936393 0.11925764 0.12972935 0.08396678 0.0984848\n",
      "  0.10441862 0.08238661 0.09940433 0.09259571]\n",
      " [0.09609809 0.09311455 0.09981034 0.09667625 0.07931939 0.1025188\n",
      "  0.11399781 0.10048509 0.11109218 0.10688762]\n",
      " [0.0916399  0.0904771  0.11174075 0.11325639 0.07501537 0.10260436\n",
      "  0.11495087 0.10034152 0.09798218 0.1019915 ]\n",
      " [0.0986592  0.11118188 0.09596182 0.10998437 0.08390758 0.08779602\n",
      "  0.10338774 0.10192705 0.10256372 0.10463066]\n",
      " [0.09999869 0.09307576 0.09007969 0.09893695 0.09078198 0.10610598\n",
      "  0.10135866 0.09995695 0.09489812 0.12480731]\n",
      " [0.09260002 0.09613678 0.1026452  0.10031199 0.09166116 0.10579359\n",
      "  0.09434399 0.10412878 0.10801981 0.10435861]\n",
      " [0.09624399 0.09987829 0.10196748 0.11251044 0.08210894 0.12307682\n",
      "  0.09248263 0.10483755 0.08707236 0.09982154]\n",
      " [0.09032546 0.08621977 0.10123264 0.10539073 0.08695481 0.10703635\n",
      "  0.10356706 0.101799   0.11124659 0.10622768]\n",
      " [0.08810405 0.10924537 0.10031017 0.09898781 0.09450483 0.09977618\n",
      "  0.10280713 0.09940138 0.1035764  0.10328664]\n",
      " [0.09688069 0.10805915 0.10504217 0.1006237  0.08263765 0.11334817\n",
      "  0.11020416 0.09046847 0.09542283 0.09731294]\n",
      " [0.09127488 0.09300603 0.12130354 0.09955598 0.08477877 0.09252066\n",
      "  0.11744409 0.08891455 0.10514064 0.10606086]\n",
      " [0.10179861 0.10050461 0.09464751 0.10144714 0.07877748 0.08835465\n",
      "  0.08987655 0.11523415 0.11588201 0.11347728]\n",
      " [0.08981111 0.09897739 0.10853498 0.10471084 0.09236803 0.09993152\n",
      "  0.11208372 0.09008017 0.09866097 0.10484134]\n",
      " [0.09236119 0.09357236 0.10658808 0.09920692 0.09128903 0.10317039\n",
      "  0.10425124 0.10623998 0.1060558  0.09726502]\n",
      " [0.11163598 0.10015314 0.10640257 0.11745664 0.07943238 0.1077477\n",
      "  0.07689826 0.09213102 0.09602334 0.11211893]\n",
      " [0.08553336 0.103686   0.10125051 0.10895018 0.08150527 0.1014028\n",
      "  0.10139567 0.09385242 0.09792725 0.1244965 ]\n",
      " [0.09424303 0.11308612 0.10625102 0.10170117 0.08124198 0.11772915\n",
      "  0.08777462 0.09298486 0.09507061 0.10991745]\n",
      " [0.10509858 0.10103996 0.10505854 0.098842   0.0885602  0.11491794\n",
      "  0.09648266 0.10159487 0.09300996 0.0953953 ]\n",
      " [0.08912587 0.09734777 0.10304482 0.09938481 0.08928391 0.10072934\n",
      "  0.10676485 0.10553373 0.10116914 0.10761563]\n",
      " [0.09386218 0.09843562 0.09486613 0.10360578 0.09553523 0.10831484\n",
      "  0.11538625 0.09499692 0.08663205 0.10836492]\n",
      " [0.09786589 0.09835064 0.09756216 0.09966757 0.09124338 0.10816303\n",
      "  0.09632523 0.11385501 0.09673022 0.10023686]\n",
      " [0.08784712 0.11117542 0.10965434 0.11537219 0.08390854 0.09163399\n",
      "  0.11793233 0.09428444 0.10050379 0.08768778]\n",
      " [0.10597733 0.09773859 0.09993988 0.11255355 0.0816967  0.0976446\n",
      "  0.10920584 0.1048778  0.10110055 0.08926516]\n",
      " [0.10595063 0.11379516 0.09882353 0.12554866 0.08114455 0.1032261\n",
      "  0.09744929 0.09006581 0.09820504 0.08579116]] (158.866 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ef7b34fe3091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;31m# if __name__ == \"__main__\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ef7b34fe3091>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m       hooks=[logging_hook])\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;31m# Evaluate the model and print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1451\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1452\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1060\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1133\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "#https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=20000,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)\n",
    "\n",
    "main(2)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
