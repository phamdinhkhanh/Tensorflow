{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0e8cb9c9ca5a>:35: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "# If the training and test sets aren't stored locally, download them.\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.request.urlopen(IRIS_TEST_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "  filename=IRIS_TRAINING,\n",
    "  target_dtype=np.int,\n",
    "  features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "  filename=IRIS_TEST,\n",
    "  target_dtype=np.int,\n",
    "  features_dtype=np.float32)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029ED7DD2F28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'tmp/iris_model'}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 30 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns = feature_columns,\n",
    "                                           hidden_units = [10, 20, 30],\n",
    "                                           n_classes = 3,\n",
    "                                           model_dir = 'tmp/iris_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_input_train():\n",
    "    X = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return X, y\n",
    "\n",
    "def get_input_test():\n",
    "    X = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.03860173, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 297.216\n",
      "INFO:tensorflow:loss = 0.038086493, step = 2101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.263\n",
      "INFO:tensorflow:loss = 0.037421968, step = 2201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.289\n",
      "INFO:tensorflow:loss = 0.035448637, step = 2301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.414\n",
      "INFO:tensorflow:loss = 0.036406215, step = 2401 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.892\n",
      "INFO:tensorflow:loss = 0.035814237, step = 2501 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.079\n",
      "INFO:tensorflow:loss = 0.035006054, step = 2601 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.941\n",
      "INFO:tensorflow:loss = 0.033904266, step = 2701 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.169\n",
      "INFO:tensorflow:loss = 0.034046523, step = 2801 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.38\n",
      "INFO:tensorflow:loss = 0.032915737, step = 2901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.341\n",
      "INFO:tensorflow:loss = 0.03308205, step = 3001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.062\n",
      "INFO:tensorflow:loss = 0.031695437, step = 3101 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.134\n",
      "INFO:tensorflow:loss = 0.03116044, step = 3201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.546\n",
      "INFO:tensorflow:loss = 0.0314736, step = 3301 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.289\n",
      "INFO:tensorflow:loss = 0.030418724, step = 3401 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.718\n",
      "INFO:tensorflow:loss = 0.029709773, step = 3501 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.106\n",
      "INFO:tensorflow:loss = 0.02863029, step = 3601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.907\n",
      "INFO:tensorflow:loss = 0.026599728, step = 3701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.702\n",
      "INFO:tensorflow:loss = 0.035708368, step = 3801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.785\n",
      "INFO:tensorflow:loss = 0.025680874, step = 3901 (0.226 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.033384833.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x0000029ED55AF128>, 'hidden_units': [10, 20, 30], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x0000029ED1D64158>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn = get_input_train, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Xem đồ thị của mạng nơ ron bằng cách vào folder hiện tại của commandline và gõ lệnh:\n",
    "\n",
    "`tensorboard --logdir tmp\\iris_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-10-23-04:51:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-23-04:51:09\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.96666664, global_step = 2000, loss = 0.0840668\n",
      "Accuracy on test: 96.67 %\n"
     ]
    }
   ],
   "source": [
    "acc = classifier.evaluate(input_fn = get_input_test, steps = 1)['accuracy']\n",
    "print('Accuracy on test: {:.2f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Sample: [[6.4 3.2 4.5 1.5]\n",
      " [5.8 3.1 5.  1.7]]\n",
      "Prediction classes: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict for new samples\n",
    "def new_samples():\n",
    "    return np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5],\n",
    "        [5.8, 3.1, 5.0, 1.7]], dtype = np.float32)\n",
    "\n",
    "pred = list(classifier.predict(input_fn = new_samples))\n",
    "print('Sample: %s'%str(new_samples()))\n",
    "print('Prediction classes: %s'%pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Sử dụng Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_train = pd.read_csv(IRIS_TRAINING, header = 0, \n",
    "                       names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                       encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "pd_test = pd.read_csv(IRIS_TEST, header = 0, \n",
    "                      names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                      encoding = 'utf-8', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in pd_train.keys()[:-1]:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'SepLen': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float64>, 'SepHei': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float64>, 'PenLen': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float64>, 'PenHei': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=float64>}, <tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int64>)\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/guide/datasets_for_estimators\n",
    "def train_input_fn(features, labels, batch_size):    \n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "print(train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], 100))\n",
    "\n",
    "\n",
    "def test_input_fn(features, labels, batch_size):    \n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# print(test_input_fn(pd_test.iloc[:, :-1], pd_test.iloc[:, -1], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tmp/iris_model_v2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029EDC8BFB00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model_v2\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tmp/iris_model_v2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.040449172, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 170.064\n",
      "INFO:tensorflow:loss = 0.0616457, step = 2101 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.616\n",
      "INFO:tensorflow:loss = 0.038828388, step = 2201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.275\n",
      "INFO:tensorflow:loss = 0.03976554, step = 2301 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.201\n",
      "INFO:tensorflow:loss = 0.04488738, step = 2401 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.264\n",
      "INFO:tensorflow:loss = 0.03512959, step = 2501 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.401\n",
      "INFO:tensorflow:loss = 0.040248968, step = 2601 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.492\n",
      "INFO:tensorflow:loss = 0.055704564, step = 2701 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.109\n",
      "INFO:tensorflow:loss = 0.039551154, step = 2801 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.753\n",
      "INFO:tensorflow:loss = 0.04209871, step = 2901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.939\n",
      "INFO:tensorflow:loss = 0.04126098, step = 3001 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.589\n",
      "INFO:tensorflow:loss = 0.053857684, step = 3101 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.034\n",
      "INFO:tensorflow:loss = 0.040825333, step = 3201 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.452\n",
      "INFO:tensorflow:loss = 0.046543512, step = 3301 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.85\n",
      "INFO:tensorflow:loss = 0.06488815, step = 3401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.424\n",
      "INFO:tensorflow:loss = 0.039714325, step = 3501 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.141\n",
      "INFO:tensorflow:loss = 0.08742438, step = 3601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.652\n",
      "INFO:tensorflow:loss = 0.03490438, step = 3701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.06\n",
      "INFO:tensorflow:loss = 0.03408143, step = 3801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.845\n",
      "INFO:tensorflow:loss = 0.028535742, step = 3901 (0.404 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into tmp/iris_model_v2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06176512.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.estimator.python.estimator.dnn.DNNEstimator at 0x29edc8bf908>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a new classifier\n",
    "# Build 3 layer DNN with 10, 20, 30 units respectively.\n",
    "classifier2 = tf.contrib.estimator.DNNEstimator(feature_columns = my_feature_columns,\n",
    "                                           hidden_units = [10, 20, 30],\n",
    "                                           head = tf.contrib.estimator.multi_class_head(n_classes=3),\n",
    "                                           optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                     learning_rate=0.1,\n",
    "                                                     l1_regularization_strength=0.001\n",
    "                                           ),\n",
    "                                           model_dir = 'tmp/iris_model_v2')\n",
    "\n",
    "#help(tf.contrib.estimator.DNNEstimator)\n",
    "classifier2.train(input_fn = lambda:train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], 100), steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1088\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                        sigcls=Signature)\n\u001b[0m\u001b[0;32m   1090\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2157\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{!r} is not a callable object'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ({'SepLen': <tf.Tensor 'IteratorGetNext_2:3' shape=(?,) dtype=float64>, 'SepHei': <tf.Tensor 'IteratorGetNext_2:2' shape=(?,) dtype=float64>, 'PenLen': <tf.Tensor 'IteratorGetNext_2:1' shape=(?,) dtype=float64>, 'PenHei': <tf.Tensor 'IteratorGetNext_2:0' shape=(?,) dtype=float64>}, <tf.Tensor 'IteratorGetNext_2:4' shape=(?,) dtype=int64>) is not a callable object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dd22f8030b8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy on test: {:.2f} %'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    461\u001b[0m         (scaffold, update_op,\n\u001b[0;32m    462\u001b[0m          \u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_hooks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_build_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m              input_fn, hooks, checkpoint_path)\n\u001b[0m\u001b[0;32m    464\u001b[0m         return self._evaluate_run(\n\u001b[0;32m    465\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_build_graph\u001b[1;34m(self, input_fn, hooks, checkpoint_path)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     features, labels, input_hooks = (\n\u001b[0;32m   1460\u001b[0m         self._get_features_and_labels_from_input_fn(input_fn,\n\u001b[1;32m-> 1461\u001b[1;33m                                                     model_fn_lib.ModeKeys.EVAL))\n\u001b[0m\u001b[0;32m   1462\u001b[0m     estimator_spec = self._call_model_fn(\n\u001b[0;32m   1463\u001b[0m         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1009\u001b[0m           lambda: self._call_input_fn(input_fn, mode))\n\u001b[0;32m   1010\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_input_fn_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1089\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minput_fn\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \"\"\"\n\u001b[1;32m-> 1091\u001b[1;33m     \u001b[0minput_fn_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'mode'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_fn_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\function_utils.py\u001b[0m in \u001b[0;36mfn_args\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_callable_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_bounded_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'self'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    214\u001b[0m   return next((d.decorator_argspec\n\u001b[0;32m    215\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                if d.decorator_argspec is not None), _getfullargspec(target))\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[1;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unsupported callable'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported callable"
     ]
    }
   ],
   "source": [
    "acc = classifier2.evaluate(input_fn = train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], 100), steps = 1)['accuracy']\n",
    "print('Accuracy on test: {:.2f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Sử dụng Estimator\n",
    "\n",
    "https://www.tensorflow.org/guide/custom_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    \"Xây dựng mạng DNN với 3 layer ẩn, và xác xuất dropout các unit là 0.1\"\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units = units, activation = tf.nn.relu)\n",
    "        \n",
    "        #Tính giá trị xác xuất cho mỗi class\n",
    "        logits = tf.layers.dense(net, params['n_classes'], activation = tf.nn.softmax)\n",
    "        \n",
    "        #Tính class dự báo.\n",
    "        predicted_classes = tf.argmax(logits, 1)\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {\n",
    "                'class_ids': predicted_classes[:, tf.newaxis],\n",
    "                'probability': tf.nn.softmax(logits),\n",
    "                'logits':logits\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "        \n",
    "        #Tính loss.\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
    "        \n",
    "        #Đánh giá mô hình.\n",
    "        accuracy = tf.metrics.accuracy(labels = labels,\n",
    "                                      predictions = predicted_classes,\n",
    "                                      name = 'acc_op')\n",
    "        \n",
    "        metrics = {'accuracy': accuracy}\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        \n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss = loss, eval_metric_ops = metrics\n",
    "            )\n",
    "        \n",
    "        #Tạo training operation\n",
    "        assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate = 0.1)\n",
    "        train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_train = pd.read_csv(IRIS_TRAINING, header = 0, \n",
    "                       names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                       encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "pd_test = pd.read_csv(IRIS_TEST, header = 0, \n",
    "                      names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                      encoding = 'utf-8', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = pd_train, pd_train.pop('Class')\n",
    "test_X, test_y = pd_test, pd_test.pop('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_X.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpxoqdkh75\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LAPTOP~1\\\\AppData\\\\Local\\\\Temp\\\\tmpxoqdkh75', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029EDC65EC18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng 3 hidden layer với số units lần lượt là 10, 20, 30 ở mỗi layer.\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        'hidden_units': [10, 20, 30],\n",
    "        'n_classes': 3,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PenLen': <tf.Tensor 'IteratorGetNext_3:0' shape=(?,) dtype=float64>,\n",
       "  'SepHei': <tf.Tensor 'IteratorGetNext_3:1' shape=(?,) dtype=float64>,\n",
       "  'SepLen': <tf.Tensor 'IteratorGetNext_3:2' shape=(?,) dtype=float64>},\n",
       " <tf.Tensor 'IteratorGetNext_3:3' shape=(?,) dtype=float64>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_input_fn(train_X, train_y, batch_size = 100)\n",
    "train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpxoqdkh75\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.2129021, step = 1\n",
      "INFO:tensorflow:global_step/sec: 168.794\n",
      "INFO:tensorflow:loss = 0.6517562, step = 101 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.305\n",
      "INFO:tensorflow:loss = 0.61773306, step = 201 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.29\n",
      "INFO:tensorflow:loss = 0.6034691, step = 301 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.847\n",
      "INFO:tensorflow:loss = 0.5990098, step = 401 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.049\n",
      "INFO:tensorflow:loss = 0.5822122, step = 501 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.487\n",
      "INFO:tensorflow:loss = 0.58918834, step = 601 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.341\n",
      "INFO:tensorflow:loss = 0.5991426, step = 701 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.212\n",
      "INFO:tensorflow:loss = 0.5764382, step = 801 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.398\n",
      "INFO:tensorflow:loss = 0.5864351, step = 901 (0.442 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpxoqdkh75\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5889306.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x29edc65e438>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_steps = 1000\n",
    "# Train mô hình\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_X, train_y, batch_size),\n",
    "    steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-25-12:37:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpxoqdkh75\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-25-12:38:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, global_step = 1000, loss = 0.5852082\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpxoqdkh75\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_X, test_y, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predict model\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepLen': [5.1, 5.9, 6.9],\n",
    "    'SepHei': [3.3, 3.0, 3.1],\n",
    "    'PenLen': [1.7, 4.2, 5.4],\n",
    "    'PenHei': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "input_fn=lambda:eval_input_fn(predict_x,\n",
    "                                        labels=None,\n",
    "                                        batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"1\" (57.5%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"2\" (56.4%), expected \"Versicolor\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probability'][class_id]\n",
    "\n",
    "        print(template.format(class_id,\n",
    "                              100 * probability, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
