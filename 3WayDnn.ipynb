{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0e8cb9c9ca5a>:35: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "# If the training and test sets aren't stored locally, download them.\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.request.urlopen(IRIS_TEST_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "  filename=IRIS_TRAINING,\n",
    "  target_dtype=np.int,\n",
    "  features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "  filename=IRIS_TEST,\n",
    "  target_dtype=np.int,\n",
    "  features_dtype=np.float32)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C8FBF91208>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'tmp/iris_model'}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 30 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns = feature_columns,\n",
    "                                           hidden_units = [10, 20, 30],\n",
    "                                           n_classes = 3,\n",
    "                                           model_dir = 'tmp/iris_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_input_train():\n",
    "    X = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return X, y\n",
    "\n",
    "def get_input_test():\n",
    "    X = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1535661, step = 1\n",
      "INFO:tensorflow:global_step/sec: 135.446\n",
      "INFO:tensorflow:loss = 0.10913229, step = 101 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.365\n",
      "INFO:tensorflow:loss = 0.07016535, step = 201 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.487\n",
      "INFO:tensorflow:loss = 0.061482508, step = 301 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.035\n",
      "INFO:tensorflow:loss = 0.05725072, step = 401 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.489\n",
      "INFO:tensorflow:loss = 0.054212973, step = 501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.488\n",
      "INFO:tensorflow:loss = 0.05156541, step = 601 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.482\n",
      "INFO:tensorflow:loss = 0.049613845, step = 701 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.379\n",
      "INFO:tensorflow:loss = 0.049233127, step = 801 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.037\n",
      "INFO:tensorflow:loss = 0.04689847, step = 901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.265\n",
      "INFO:tensorflow:loss = 0.047157384, step = 1001 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.974\n",
      "INFO:tensorflow:loss = 0.0453231, step = 1101 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.268\n",
      "INFO:tensorflow:loss = 0.044575986, step = 1201 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.485\n",
      "INFO:tensorflow:loss = 0.04354943, step = 1301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.366\n",
      "INFO:tensorflow:loss = 0.042687763, step = 1401 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.073\n",
      "INFO:tensorflow:loss = 0.041951574, step = 1501 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.038\n",
      "INFO:tensorflow:loss = 0.04138611, step = 1601 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.368\n",
      "INFO:tensorflow:loss = 0.040571373, step = 1701 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.487\n",
      "INFO:tensorflow:loss = 0.039888393, step = 1801 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.373\n",
      "INFO:tensorflow:loss = 0.03920037, step = 1901 (0.475 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.039036572.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001C8FBF910F0>, 'hidden_units': [10, 20, 30], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x000001C8F5F7BA60>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn = get_input_train, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Xem đồ thị của mạng nơ ron bằng cách vào folder hiện tại của commandline và gõ lệnh:\n",
    "\n",
    "`tensorboard --logdir tmp\\iris_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-10-23-04:51:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-23-04:51:09\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.96666664, global_step = 2000, loss = 0.0840668\n",
      "Accuracy on test: 96.67 %\n"
     ]
    }
   ],
   "source": [
    "acc = classifier.evaluate(input_fn = get_input_test, steps = 1)['accuracy']\n",
    "print('Accuracy on test: {:.2f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/iris_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Sample: [[6.4 3.2 4.5 1.5]\n",
      " [5.8 3.1 5.  1.7]]\n",
      "Prediction classes: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Predict for new samples\n",
    "def new_samples():\n",
    "    return np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5],\n",
    "        [5.8, 3.1, 5.0, 1.7]], dtype = np.float32)\n",
    "\n",
    "pred = list(classifier.predict(input_fn = new_samples))\n",
    "print('Sample: %s'%str(new_sample()))\n",
    "print('Prediction classes: %s'%pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Sử dụng Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_train = pd.read_csv(IRIS_TRAINING, header = 0, \n",
    "                       names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                       encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "pd_test = pd.read_csv(IRIS_TEST, header = 0, \n",
    "                      names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                      encoding = 'utf-8', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in pd_train.keys()[:-1]:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'SepLen': <tf.Tensor 'IteratorGetNext_10:3' shape=(?,) dtype=float64>, 'SepHei': <tf.Tensor 'IteratorGetNext_10:2' shape=(?,) dtype=float64>, 'PenLen': <tf.Tensor 'IteratorGetNext_10:1' shape=(?,) dtype=float64>, 'PenHei': <tf.Tensor 'IteratorGetNext_10:0' shape=(?,) dtype=float64>}, <tf.Tensor 'IteratorGetNext_10:4' shape=(?,) dtype=int64>)\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/guide/datasets_for_estimators\n",
    "def train_input_fn(features, labels, batch_size):    \n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "print(train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], 100))\n",
    "\n",
    "\n",
    "def test_input_fn(features, labels, batch_size):    \n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# print(test_input_fn(pd_test.iloc[:, :-1], pd_test.iloc[:, -1], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tmp/iris_model_v2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F34ADCADD8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tmp/iris_model_v2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1343771, step = 1\n",
      "INFO:tensorflow:global_step/sec: 190.655\n",
      "INFO:tensorflow:loss = 0.19709973, step = 101 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.014\n",
      "INFO:tensorflow:loss = 0.0448243, step = 201 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.089\n",
      "INFO:tensorflow:loss = 0.06444687, step = 301 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.802\n",
      "INFO:tensorflow:loss = 0.05152374, step = 401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.66\n",
      "INFO:tensorflow:loss = 0.040994048, step = 501 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.448\n",
      "INFO:tensorflow:loss = 0.051608585, step = 601 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.308\n",
      "INFO:tensorflow:loss = 0.061957255, step = 701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.123\n",
      "INFO:tensorflow:loss = 0.03885824, step = 801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.915\n",
      "INFO:tensorflow:loss = 0.054688595, step = 901 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.019\n",
      "INFO:tensorflow:loss = 0.10777255, step = 1001 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.12\n",
      "INFO:tensorflow:loss = 0.06508905, step = 1101 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.238\n",
      "INFO:tensorflow:loss = 0.018963568, step = 1201 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.746\n",
      "INFO:tensorflow:loss = 0.065067895, step = 1301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.764\n",
      "INFO:tensorflow:loss = 0.04282737, step = 1401 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.998\n",
      "INFO:tensorflow:loss = 0.045118246, step = 1501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.561\n",
      "INFO:tensorflow:loss = 0.037405647, step = 1601 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.913\n",
      "INFO:tensorflow:loss = 0.08747053, step = 1701 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.533\n",
      "INFO:tensorflow:loss = 0.048439745, step = 1801 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.744\n",
      "INFO:tensorflow:loss = 0.045258533, step = 1901 (0.355 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tmp/iris_model_v2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.039481938.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.estimator.python.estimator.dnn.DNNEstimator at 0x1f34ae0ef28>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a new classifier\n",
    "# Build 3 layer DNN with 10, 20, 30 units respectively.\n",
    "classifier2 = tf.contrib.estimator.DNNEstimator(feature_columns = my_feature_columns,\n",
    "                                           hidden_units = [10, 20, 30],\n",
    "                                           head = tf.contrib.estimator.multi_class_head(n_classes=3),\n",
    "                                           optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                                     learning_rate=0.1,\n",
    "                                                     l1_regularization_strength=0.001\n",
    "                                           ),\n",
    "                                           model_dir = 'tmp/iris_model_v2')\n",
    "\n",
    "#help(tf.contrib.estimator.DNNEstimator)\n",
    "classifier2.train(input_fn = lambda:train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], 100), steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_input_fn() missing 3 required positional arguments: 'features', 'labels', and 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-04f221d8bb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy on test: {:.2f} %'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    461\u001b[0m         (scaffold, update_op,\n\u001b[0;32m    462\u001b[0m          \u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_hooks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_build_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m              input_fn, hooks, checkpoint_path)\n\u001b[0m\u001b[0;32m    464\u001b[0m         return self._evaluate_run(\n\u001b[0;32m    465\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_build_graph\u001b[1;34m(self, input_fn, hooks, checkpoint_path)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     features, labels, input_hooks = (\n\u001b[0;32m   1460\u001b[0m         self._get_features_and_labels_from_input_fn(input_fn,\n\u001b[1;32m-> 1461\u001b[1;33m                                                     model_fn_lib.ModeKeys.EVAL))\n\u001b[0m\u001b[0;32m   1462\u001b[0m     estimator_spec = self._call_model_fn(\n\u001b[0;32m   1463\u001b[0m         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1009\u001b[0m           lambda: self._call_input_fn(input_fn, mode))\n\u001b[0;32m   1010\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_input_fn_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1098\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: test_input_fn() missing 3 required positional arguments: 'features', 'labels', and 'batch_size'"
     ]
    }
   ],
   "source": [
    "acc = classifier2.evaluate(input_fn = test_input_fn, steps = 1)['accuracy']\n",
    "print('Accuracy on test: {:.2f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Sử dụng Estimator\n",
    "\n",
    "https://www.tensorflow.org/guide/custom_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    \"Xây dựng mạng DNN với 3 layer ẩn, và xác xuất dropout các unit là 0.1\"\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units = units, activation = tf.nn.relu)\n",
    "        \n",
    "        #Tính giá trị xác xuất cho mỗi class\n",
    "        logits = tf.layers.dense(net, params['n_classes'], activation = tf.nn.softmax)\n",
    "        \n",
    "        #Tính class dự báo.\n",
    "        predicted_classes = tf.argmax(logits, 1)\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {\n",
    "                'class_ids': predicted_classes[:, tf.newaxis],\n",
    "                'probability': tf.nn.softmax(logits),\n",
    "                'logits':logits\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "        \n",
    "        #Tính loss.\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
    "        \n",
    "        #Đánh giá mô hình.\n",
    "        accuracy = tf.metrics.accuracy(labels = labels,\n",
    "                                      predictions = predicted_classes,\n",
    "                                      name = 'acc_op')\n",
    "        \n",
    "        metrics = {'accuracy': accuracy}\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        \n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss = loss, eval_metric_ops = metrics\n",
    "            )\n",
    "        \n",
    "        #Tạo training operation\n",
    "        assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate = 0.1)\n",
    "        train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_train = pd.read_csv(IRIS_TRAINING, header = 0, \n",
    "                       names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                       encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "pd_test = pd.read_csv(IRIS_TEST, header = 0, \n",
    "                      names = ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Class'], \n",
    "                      encoding = 'utf-8', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = pd_train, pd_train.pop('Class')\n",
    "test_X, test_y = pd_test, pd_test.pop('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_X.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpko5k1sde\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LAPTOP~1\\\\AppData\\\\Local\\\\Temp\\\\tmpko5k1sde', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F344F08A20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Xây dựng 3 hidden layer với số units lần lượt là 10, 20, 30 ở mỗi layer.\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        'hidden_units': [10, 20, 30],\n",
    "        'n_classes': 3,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PenHei': <tf.Tensor 'IteratorGetNext_4:0' shape=(?,) dtype=float64>,\n",
       "  'PenLen': <tf.Tensor 'IteratorGetNext_4:1' shape=(?,) dtype=float64>,\n",
       "  'SepHei': <tf.Tensor 'IteratorGetNext_4:2' shape=(?,) dtype=float64>,\n",
       "  'SepLen': <tf.Tensor 'IteratorGetNext_4:3' shape=(?,) dtype=float64>},\n",
       " <tf.Tensor 'IteratorGetNext_4:4' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_input_fn(train_X, train_y, batch_size = 100)\n",
    "train_input_fn(pd_train.iloc[:, :-1], pd_train.iloc[:, -1], batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpko5k1sde\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1779083, step = 1\n",
      "INFO:tensorflow:global_step/sec: 229.836\n",
      "INFO:tensorflow:loss = 0.6757853, step = 101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.806\n",
      "INFO:tensorflow:loss = 0.6312725, step = 201 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.763\n",
      "INFO:tensorflow:loss = 0.60638124, step = 301 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.74\n",
      "INFO:tensorflow:loss = 0.5983583, step = 401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.097\n",
      "INFO:tensorflow:loss = 0.5777912, step = 501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.291\n",
      "INFO:tensorflow:loss = 0.5833523, step = 601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.98\n",
      "INFO:tensorflow:loss = 0.58493257, step = 701 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.933\n",
      "INFO:tensorflow:loss = 0.591378, step = 801 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.9\n",
      "INFO:tensorflow:loss = 0.5690014, step = 901 (0.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpko5k1sde\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5733552.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1f344f08780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_steps = 1000\n",
    "# Train mô hình\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_X, train_y, batch_size),\n",
    "    steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-23-11:51:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpdq049w0d\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-23-11:51:26\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, global_step = 1000, loss = 0.06848378\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpdq049w0d\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_X, test_y, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predict model\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepLen': [5.1, 5.9, 6.9],\n",
    "    'SepHei': [3.3, 3.0, 3.1],\n",
    "    'PenLen': [1.7, 4.2, 5.4],\n",
    "    'PenHei': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "input_fn=lambda:eval_input_fn(predict_x,\n",
    "                                        labels=None,\n",
    "                                        batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "        print(template.format(class_id,\n",
    "                              100 * probability, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
