{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026FD472D0F0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/iris_model'}\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.5520251, step = 1\n",
      "INFO:tensorflow:global_step/sec: 336.859\n",
      "INFO:tensorflow:loss = 0.18421426, step = 101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.694\n",
      "INFO:tensorflow:loss = 0.09236845, step = 201 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.687\n",
      "INFO:tensorflow:loss = 0.07277943, step = 301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.674\n",
      "INFO:tensorflow:loss = 0.06529189, step = 401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.77\n",
      "INFO:tensorflow:loss = 0.061118357, step = 501 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.006\n",
      "INFO:tensorflow:loss = 0.057754226, step = 601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.694\n",
      "INFO:tensorflow:loss = 0.055374723, step = 701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.675\n",
      "INFO:tensorflow:loss = 0.0531515, step = 801 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.976\n",
      "INFO:tensorflow:loss = 0.05184079, step = 901 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.496\n",
      "INFO:tensorflow:loss = 0.050396968, step = 1001 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.007\n",
      "INFO:tensorflow:loss = 0.049241025, step = 1101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.015\n",
      "INFO:tensorflow:loss = 0.04836098, step = 1201 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.332\n",
      "INFO:tensorflow:loss = 0.04739176, step = 1301 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.684\n",
      "INFO:tensorflow:loss = 0.046578135, step = 1401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.029\n",
      "INFO:tensorflow:loss = 0.045809757, step = 1501 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.68\n",
      "INFO:tensorflow:loss = 0.04516471, step = 1601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.019\n",
      "INFO:tensorflow:loss = 0.044436436, step = 1701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.009\n",
      "INFO:tensorflow:loss = 0.043915622, step = 1801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.49\n",
      "INFO:tensorflow:loss = 0.04326693, step = 1901 (0.250 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.042738166.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-12-07:33:43\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model\\model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-12-07:33:43\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.96666664, global_step = 2000, loss = 0.060342617\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\laptoptcc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:381: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model\\model.ckpt-2000\n",
      "New Samples, Class Predictions:    [1, 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def main():\n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.request.urlopen(IRIS_TRAINING_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.request.urlopen(IRIS_TEST_URL).read().decode('utf-8')\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  # Load datasets.\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "  classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10, 20, 10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir=\"/tmp/iris_model\")\n",
    "  # Define the training inputs\n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  # Fit model.\n",
    "  classifier.fit(input_fn=get_train_inputs, steps=2000)\n",
    "\n",
    "  # Define the test inputs\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
    "                                       steps=1)[\"accuracy\"]\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  def new_samples():\n",
    "    return np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "\n",
    "  predictions = list(classifier.predict(input_fn=new_samples))\n",
    "\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predictions))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PenHei': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=float64>,\n",
       "  'PenLen': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float64>,\n",
       "  'SepHei': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float64>,\n",
       "  'SepLen': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float64>},\n",
       " <tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "\n",
    "IRIS_TRAIN = 'iris_training.csv'\n",
    "IRIS_TEST = 'iris_test.csv'\n",
    "IRIS_TRAIN_PATH = 'http://download.tensorflow.org/data/iris_training.csv'\n",
    "IRIS_TEST_PATH = 'http://download.tensorflow.org/data/iris_test.csv'\n",
    "NAMES =  ['SepLen', 'SepHei', 'PenLen', 'PenHei', 'Species']\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.5\n",
    "STEPS = 1000\n",
    "\n",
    "def get_data(is_get_train = True, batch_size = BATCH_SIZE):\n",
    "    if is_get_train:\n",
    "        filename = IRIS_TRAIN\n",
    "        source = IRIS_TRAIN_PATH\n",
    "    else:\n",
    "        filename = IRIS_TEST\n",
    "        source = IRIS_TEST_PATH\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        raw = urllib.request.urlopen(source).read().decode('utf-8')\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(raw)\n",
    "    data_pandas = pd.read_csv(filename, header = 0, names = NAMES, encoding = 'utf-8', engine = 'python')\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_pandas.iloc[:, :-1]), data_pandas.iloc[:, -1]))\n",
    "    if is_get_train:\n",
    "        dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    else:\n",
    "        return dataset.batch(batch_size)\n",
    "    \n",
    "                       \n",
    "get_data()\n",
    "\n",
    "\n",
    "# ({'PenHei': <tf.Tensor 'IteratorGetNext_2:0' shape=(?,) dtype=float64>,\n",
    "#   'PenLen': <tf.Tensor 'IteratorGetNext_2:1' shape=(?,) dtype=float64>,\n",
    "#   'SepHei': <tf.Tensor 'IteratorGetNext_2:2' shape=(?,) dtype=float64>,\n",
    "#   'SepLen': <tf.Tensor 'IteratorGetNext_2:3' shape=(?,) dtype=float64>},\n",
    "#  <tf.Tensor 'IteratorGetNext_2:4' shape=(?,) dtype=int64>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "pd_train = pd.read_csv(IRIS_TRAIN, header = 0, \n",
    "                       names = NAMES, \n",
    "                       encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "pd_test = pd.read_csv(IRIS_TEST, header = 0, \n",
    "                      names = NAMES, \n",
    "                      encoding = 'utf-8', engine = 'python')\n",
    "\n",
    "train_X, train_y = pd_train, pd_train.pop('Species')\n",
    "test_X, test_y = pd_test, pd_test.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenLen', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PenHei', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in NAMES[:-1]:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpyldls7b1\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LAPTOP~1\\\\AppData\\\\Local\\\\Temp\\\\tmpyldls7b1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EB616C7710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpyldls7b1\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0443542, step = 1\n",
      "INFO:tensorflow:global_step/sec: 226.455\n",
      "INFO:tensorflow:loss = 0.58331424, step = 101 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.536\n",
      "INFO:tensorflow:loss = 0.5592294, step = 201 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.763\n",
      "INFO:tensorflow:loss = 0.5809977, step = 301 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.65\n",
      "INFO:tensorflow:loss = 0.60172766, step = 401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.649\n",
      "INFO:tensorflow:loss = 0.5849844, step = 501 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.77\n",
      "INFO:tensorflow:loss = 0.5955144, step = 601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.201\n",
      "INFO:tensorflow:loss = 0.5864059, step = 701 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.775\n",
      "INFO:tensorflow:loss = 0.55774426, step = 801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.785\n",
      "INFO:tensorflow:loss = 0.56472564, step = 901 (0.314 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\LAPTOP~1\\AppData\\Local\\Temp\\tmpyldls7b1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5796103.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1eb616c7400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thiết lập params để truyền vào model function\n",
    "my_params = {\n",
    "    'feature_columns': my_feature_columns,\n",
    "    'hidden_units': [10, 20 ,10],\n",
    "    'n_classes': 3\n",
    "}\n",
    "\n",
    "#Khởi tạo model function\n",
    "def my_model_fn(features, labels, mode, params):\n",
    "    #Có 3 dạng mode chính trong model tương ứng với:\n",
    "    #1. tf.estimator.ModeKeys.TRAIN: training model\n",
    "    #2. tf.estimator.ModeKeys.PREDICT: dự báo model\n",
    "    #3. tf.estimator.ModeKeys.EVAL: đánh giá model \n",
    "    #Bên dưới ta sẽ xây dựng cho mode TRAIN.\n",
    "    \n",
    "    #Khởi tạo mạng nơ ron với các 3 hidden layer:\n",
    "    #1. Input layer: được khởi tạo từ tf.feature_column.input_layer(features, feature_columns).\n",
    "    #features là các estimator của mạng nơ ron sẽ được map với Dataset thông qua tên trong feature_columns.\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    #2. Các hidden layers được khởi tạo bằng vòng lặp: Mỗi layer là một fully connected layer được khởi tạo\n",
    "    #từ hàm tf.layers.dense(inputs, units, activation): \n",
    "    #trong đó inputs là một tensor (chính là các layer trước), units là số đơn vị của layer, activation là hàm kích hoạt.\n",
    "    for units in params['hidden_units']:\n",
    "         net = tf.layers.dense(net, units = units, activation = tf.nn.relu)\n",
    "    #3. Output layer: Tính toán giá trị logits ứng với mỗi classes. Do đó ta cần một fully connected layers \n",
    "    #Kết nối mỗi layer trước đó với 3 units là 3 class.  Thông qua hàm kích hoạt softmax để tính xác xuất ước lượng.\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation = tf.nn.softmax)\n",
    "    \n",
    "    #Hàm loss function: Đo lường giá trị entropy giữa phân phối dự báo từ từ layer logits và giá trị labels thực tế (ground truth)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
    "    #Optimizer\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate = LEARNING_RATE)\n",
    "    #Khởi tạo train operations tối thiểu hóa loss funtion\n",
    "    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode = tf.estimator.ModeKeys.TRAIN, loss = loss, train_op = train_op)\n",
    "\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn = my_model_fn,\n",
    "    params = my_params #params sẽ được pass vào model_fn. \n",
    "    #Nội dung của params chính là các phần tử: feature_columns, units, n_class ta đã sử dụng trong my_mode_fn\n",
    ")\n",
    "\n",
    "\n",
    "# #train model. Bước này ta cần xác định hàm input_fn là gì, số bước huấn luyện.\n",
    "classifier.train(\n",
    "    input_fn = lambda:get_data(), #Lưu ý luôn phải để input_fn dưới dạng hàm lambda để có thể đưa dữ liệu vào huấn luyện theo iterator\n",
    "    steps = STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PenHei': <tf.Tensor 'IteratorGetNext_3:0' shape=(?,) dtype=float64>,\n",
       "  'PenLen': <tf.Tensor 'IteratorGetNext_3:1' shape=(?,) dtype=float64>,\n",
       "  'SepHei': <tf.Tensor 'IteratorGetNext_3:2' shape=(?,) dtype=float64>,\n",
       "  'SepLen': <tf.Tensor 'IteratorGetNext_3:3' shape=(?,) dtype=float64>},\n",
       " <tf.Tensor 'IteratorGetNext_3:4' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn(train_X, train_y, batch_size = BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
